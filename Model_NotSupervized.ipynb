{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436f8c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "âœ… Dati caricati: X_scaled (310034, 42), X_latent (310034, 16)\n",
      "\n",
      "================ Ensemble Model 1/3 ================\n",
      "\n",
      "ğŸ—ï¸ Avvio Autoencoder Ensemble...\n",
      "Epoch 1/10 [â”â”â”---------------------------] loss=0.004001 val=0.170712 time=4.37s\n",
      "Epoch 2/10 [â”â”â”â”â”â”------------------------] loss=0.000177 val=0.175488 time=7.48s\n",
      "Epoch 3/10 [â”â”â”â”â”â”â”â”â”---------------------] loss=0.000157 val=0.175815 time=10.97s\n",
      "Epoch 4/10 [â”â”â”â”â”â”â”â”â”â”â”â”------------------] loss=0.000145 val=0.178025 time=14.21s\n",
      "Epoch 5/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---------------] loss=0.000140 val=0.178036 time=17.63s\n",
      "Epoch 6/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”------------] loss=0.000135 val=0.178624 time=20.52s\n",
      "Epoch 7/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---------] loss=0.000135 val=0.175581 time=23.46s\n",
      "Epoch 8/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”------] loss=0.000132 val=0.179385 time=27.17s\n",
      "Epoch 9/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---] loss=0.000152 val=0.177081 time=30.94s\n",
      "Epoch 10/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”] loss=0.000131 val=0.174441 time=35.79s\n",
      "\n",
      "================ Ensemble Model 2/3 ================\n",
      "\n",
      "ğŸ—ï¸ Avvio Autoencoder Ensemble...\n",
      "Epoch 1/10 [â”â”â”---------------------------] loss=0.003922 val=0.182948 time=4.62s\n",
      "Epoch 2/10 [â”â”â”â”â”â”------------------------] loss=0.000163 val=0.188460 time=7.55s\n",
      "Epoch 3/10 [â”â”â”â”â”â”â”â”â”---------------------] loss=0.000140 val=0.186991 time=10.39s\n",
      "Epoch 4/10 [â”â”â”â”â”â”â”â”â”â”â”â”------------------] loss=0.000132 val=0.188030 time=13.60s\n",
      "Epoch 5/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---------------] loss=0.000125 val=0.188009 time=17.60s\n",
      "Epoch 6/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”------------] loss=0.000122 val=0.189665 time=21.17s\n",
      "Epoch 7/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---------] loss=0.000122 val=0.197152 time=25.38s\n",
      "Epoch 8/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”------] loss=0.000123 val=0.197348 time=29.34s\n",
      "Epoch 9/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---] loss=0.000117 val=0.202565 time=33.38s\n",
      "Epoch 10/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”] loss=0.000120 val=0.198497 time=37.16s\n",
      "\n",
      "================ Ensemble Model 3/3 ================\n",
      "\n",
      "ğŸ—ï¸ Avvio Autoencoder Ensemble...\n",
      "Epoch 1/10 [â”â”â”---------------------------] loss=0.003608 val=0.195098 time=6.34s\n",
      "Epoch 2/10 [â”â”â”â”â”â”------------------------] loss=0.000172 val=0.201151 time=9.63s\n",
      "Epoch 3/10 [â”â”â”â”â”â”â”â”â”---------------------] loss=0.000154 val=0.187532 time=13.44s\n",
      "Epoch 4/10 [â”â”â”â”â”â”â”â”â”â”â”â”------------------] loss=0.000139 val=0.186563 time=16.93s\n",
      "Epoch 5/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---------------] loss=0.000134 val=0.180007 time=20.48s\n",
      "Epoch 6/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”------------] loss=0.000136 val=0.168868 time=24.81s\n",
      "Epoch 7/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---------] loss=0.000129 val=0.174118 time=28.13s\n",
      "Epoch 8/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”------] loss=0.000126 val=0.178220 time=31.35s\n",
      "Epoch 9/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”---] loss=0.000125 val=0.183982 time=34.52s\n",
      "Epoch 10/10 [â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”] loss=0.000116 val=0.179971 time=37.70s\n",
      "\n",
      "âœ… Embeddings ensemble generati: (310034, 16)\n",
      "ğŸ“Œ Anomalie rilevate: 49643/310034 (16.01%)\n",
      "ğŸ’¾ Salvataggio completato.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Ensemble Autoencoder + Isolation Forest (con Pretty Logger)\n",
    "# ==========================================================\n",
    "\n",
    "import os, random, gc, time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# -------------------------------\n",
    "# âœ… Setup riproducibilitÃ \n",
    "# -------------------------------\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# -------------------------------\n",
    "# âœ… Callback grafico training\n",
    "# -------------------------------\n",
    "class PrettyTrainingLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_epochs, bar_length=30):\n",
    "        super().__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.bar_length = bar_length\n",
    "        self.start_time = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "        print(f\"\\nğŸ—ï¸ Avvio Autoencoder Ensemble...\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch += 1\n",
    "        loss = logs.get(\"loss\", 0)\n",
    "        val = logs.get(\"val_loss\", 0)\n",
    "        elapsed = time.time() - self.start_time\n",
    "\n",
    "        progress = epoch / self.total_epochs\n",
    "        filled = int(self.bar_length * progress)\n",
    "        bar = \"â”\" * filled + \"-\" * (self.bar_length - filled)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{self.total_epochs} [{bar}] \"\n",
    "              f\"loss={loss:.6f} val={val:.6f} time={elapsed:.2f}s\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1ï¸âƒ£ Caricamento dati\n",
    "# -------------------------------\n",
    "X_scaled = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_autoencoder_final.npy\")\n",
    "X_latent = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_autoencoder_latent.npy\")\n",
    "print(f\"âœ… Dati caricati: X_scaled {X_scaled.shape}, X_latent {X_latent.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2ï¸âƒ£ Configurazione ensemble Autoencoder\n",
    "# -------------------------------\n",
    "n_ensemble = 3\n",
    "latent_dim = X_latent.shape[1]\n",
    "input_dim = X_scaled.shape[1]\n",
    "ensemble_latent = []\n",
    "epochs = 10\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "for i in range(n_ensemble):\n",
    "    print(f\"\\n================ Ensemble Model {i+1}/{n_ensemble} ================\")\n",
    "\n",
    "    # Architettura Autoencoder identica\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    encoded = Dense(latent_dim, activation='relu', name='latent_vector')(encoded)\n",
    "    decoded = Dense(32, activation='relu')(encoded)\n",
    "    decoded = Dense(64, activation='relu')(decoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Logger console training\n",
    "    logger = PrettyTrainingLogger(total_epochs=epochs)\n",
    "\n",
    "    autoencoder.fit(\n",
    "        X_scaled, X_scaled,\n",
    "        epochs=epochs,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=0,\n",
    "        callbacks=[logger]\n",
    "    )\n",
    "\n",
    "    # Estrazione embeddings\n",
    "    encoder = Model(inputs=input_layer, outputs=autoencoder.get_layer('latent_vector').output)\n",
    "    X_latent_i = encoder.predict(X_scaled, verbose=0)\n",
    "    ensemble_latent.append(X_latent_i)\n",
    "\n",
    "# -------------------------------\n",
    "# 3ï¸âƒ£ Media embeddings ensemble\n",
    "# -------------------------------\n",
    "X_ensemble_latent = np.mean(np.stack(ensemble_latent, axis=0), axis=0)\n",
    "print(f\"\\nâœ… Embeddings ensemble generati: {X_ensemble_latent.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4ï¸âƒ£ Addestramento Isolation Forest\n",
    "# -------------------------------\n",
    "iso = IsolationForest(n_estimators=300, contamination='auto', random_state=42)\n",
    "iso.fit(X_ensemble_latent)\n",
    "\n",
    "scores = iso.score_samples(X_ensemble_latent)\n",
    "anomalies = iso.predict(X_ensemble_latent)\n",
    "\n",
    "# -------------------------------\n",
    "# 5ï¸âƒ£ Statistiche\n",
    "# -------------------------------\n",
    "n_anomalies = (anomalies == -1).sum()\n",
    "print(f\"ğŸ“Œ Anomalie rilevate: {n_anomalies}/{X_scaled.shape[0]} \"\n",
    "      f\"({n_anomalies/X_scaled.shape[0]*100:.2f}%)\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6ï¸âƒ£ Salvataggio output\n",
    "# -------------------------------\n",
    "np.save(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_ensemble_latent.npy\", X_ensemble_latent)\n",
    "np.save(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\anomalies.npy\", anomalies)\n",
    "\n",
    "print(\"ğŸ’¾ Salvataggio completato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bf1856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings ensemble: (310034, 16), Anomalie: (310034,)\n",
      "âœ… Dataset pronto per analisi esplorativa: (310034, 20)\n",
      "\n",
      "ğŸ“Š Percentuale anomalie per label_technique:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_samples</th>\n",
       "      <th>num_anomalies</th>\n",
       "      <th>%_anomalous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>3119</td>\n",
       "      <td>3119</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1046</th>\n",
       "      <td>16020</td>\n",
       "      <td>16020</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1592</th>\n",
       "      <td>20382</td>\n",
       "      <td>20382</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1595</th>\n",
       "      <td>8104</td>\n",
       "      <td>8104</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1587</th>\n",
       "      <td>262409</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_samples  num_anomalies  %_anomalous\n",
       "label_technique                                           \n",
       "Other                     3119           3119       100.00\n",
       "T1046                    16020          16020       100.00\n",
       "T1592                    20382          20382       100.00\n",
       "T1595                     8104           8104       100.00\n",
       "T1587                   262409           2018         0.77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Dataset con label e anomalie salvato (parquet).\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Analisi anomalie + associazione label (semi-supervised)\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# 1ï¸âƒ£ Caricamento embeddings e anomalie\n",
    "# -------------------------------\n",
    "X_ensemble_latent = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_ensemble_latent.npy\")\n",
    "anomalies = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\anomalies.npy\")\n",
    "print(f\"âœ… Embeddings ensemble: {X_ensemble_latent.shape}, Anomalie: {anomalies.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2ï¸âƒ£ Creazione DataFrame per analisi\n",
    "# -------------------------------\n",
    "df_latent = pd.DataFrame(X_ensemble_latent, columns=[f'latent_{i}' for i in range(X_ensemble_latent.shape[1])])\n",
    "\n",
    "# Associare solo label_technique (array di stringhe)\n",
    "labels = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\labels.npy\", allow_pickle=True)\n",
    "df_latent['label_technique'] = labels\n",
    "\n",
    "# Se non hai label_tactic, puoi mettere 'unknown' oppure creare un array con valori fissi\n",
    "df_latent['label_tactic'] = ['unknown'] * len(labels)\n",
    "\n",
    "# Anomalie\n",
    "df_latent['anomaly'] = anomalies\n",
    "df_latent['anomaly_flag'] = df_latent['anomaly'].map({1:0, -1:1})  # 1 = anomalia, 0 = normale\n",
    "\n",
    "print(f\"âœ… Dataset pronto per analisi esplorativa: {df_latent.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3ï¸âƒ£ Statistiche anomalie per tipo di attacco\n",
    "# -------------------------------\n",
    "tech_anomalies = df_latent.groupby('label_technique')['anomaly_flag'].sum()\n",
    "tech_total = df_latent['label_technique'].value_counts()\n",
    "tech_pct = (tech_anomalies / tech_total * 100).round(2)\n",
    "\n",
    "anomaly_summary = pd.DataFrame({\n",
    "    'total_samples': tech_total,\n",
    "    'num_anomalies': tech_anomalies,\n",
    "    '%_anomalous': tech_pct\n",
    "}).sort_values('%_anomalous', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ“Š Percentuale anomalie per label_technique:\")\n",
    "display(anomaly_summary)\n",
    "\n",
    "# -------------------------------\n",
    "# 4ï¸âƒ£ Salvataggio dataset completo per analisi successive\n",
    "# -------------------------------\n",
    "df_latent.to_parquet(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_ensemble_latent_labeled.parquet\", index=False)\n",
    "print(\"ğŸ’¾ Dataset con label e anomalie salvato (parquet).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b46629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings ensemble: (310034, 16), Anomalie: (310034,), Labels: (310034,)\n",
      "âœ… Dataset pronto: (310034, 20)\n",
      "\n",
      "ğŸ“Š Percentuale anomalie per label_technique:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_samples</th>\n",
       "      <th>num_anomalies</th>\n",
       "      <th>%_anomalous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>3119</td>\n",
       "      <td>3119</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1046</th>\n",
       "      <td>16020</td>\n",
       "      <td>16020</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1592</th>\n",
       "      <td>20382</td>\n",
       "      <td>20382</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1595</th>\n",
       "      <td>8104</td>\n",
       "      <td>8104</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1587</th>\n",
       "      <td>262409</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_samples  num_anomalies  %_anomalous\n",
       "label_technique                                           \n",
       "Other                     3119           3119       100.00\n",
       "T1046                    16020          16020       100.00\n",
       "T1592                    20382          20382       100.00\n",
       "T1595                     8104           8104       100.00\n",
       "T1587                   262409           2018         0.77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ Numero totale anomalie: 49643\n",
      "\n",
      "ğŸ“Œ Distribuzione anomalie per label_technique:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_technique\n",
       "T1592    20382\n",
       "T1046    16020\n",
       "T1595     8104\n",
       "Other     3119\n",
       "T1587     2018\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Media feature latenti (anomalia vs normale):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latent_0</th>\n",
       "      <th>latent_1</th>\n",
       "      <th>latent_2</th>\n",
       "      <th>latent_3</th>\n",
       "      <th>latent_4</th>\n",
       "      <th>latent_5</th>\n",
       "      <th>latent_6</th>\n",
       "      <th>latent_7</th>\n",
       "      <th>latent_8</th>\n",
       "      <th>latent_9</th>\n",
       "      <th>latent_10</th>\n",
       "      <th>latent_11</th>\n",
       "      <th>latent_12</th>\n",
       "      <th>latent_13</th>\n",
       "      <th>latent_14</th>\n",
       "      <th>latent_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anomaly_flag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594355</td>\n",
       "      <td>0.257848</td>\n",
       "      <td>2.062619</td>\n",
       "      <td>2.827694</td>\n",
       "      <td>1.011494</td>\n",
       "      <td>0.637380</td>\n",
       "      <td>1.703569</td>\n",
       "      <td>1.489913</td>\n",
       "      <td>3.017656</td>\n",
       "      <td>0.584059</td>\n",
       "      <td>3.338214</td>\n",
       "      <td>1.321551</td>\n",
       "      <td>0.485862</td>\n",
       "      <td>2.431566</td>\n",
       "      <td>0.456764</td>\n",
       "      <td>0.923206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.584588</td>\n",
       "      <td>1.867103</td>\n",
       "      <td>1.516809</td>\n",
       "      <td>1.602032</td>\n",
       "      <td>1.413490</td>\n",
       "      <td>0.445802</td>\n",
       "      <td>1.105261</td>\n",
       "      <td>2.729810</td>\n",
       "      <td>2.104894</td>\n",
       "      <td>0.825477</td>\n",
       "      <td>2.629362</td>\n",
       "      <td>2.701282</td>\n",
       "      <td>2.267837</td>\n",
       "      <td>1.791311</td>\n",
       "      <td>2.285766</td>\n",
       "      <td>1.485759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              latent_0  latent_1  latent_2  latent_3  latent_4  latent_5  \\\n",
       "anomaly_flag                                                               \n",
       "0             0.594355  0.257848  2.062619  2.827694  1.011494  0.637380   \n",
       "1             1.584588  1.867103  1.516809  1.602032  1.413490  0.445802   \n",
       "\n",
       "              latent_6  latent_7  latent_8  latent_9  latent_10  latent_11  \\\n",
       "anomaly_flag                                                                 \n",
       "0             1.703569  1.489913  3.017656  0.584059   3.338214   1.321551   \n",
       "1             1.105261  2.729810  2.104894  0.825477   2.629362   2.701282   \n",
       "\n",
       "              latent_12  latent_13  latent_14  latent_15  \n",
       "anomaly_flag                                              \n",
       "0              0.485862   2.431566   0.456764   0.923206  \n",
       "1              2.267837   1.791311   2.285766   1.485759  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ Metriche semi-supervised (Isolation Forest):\n",
      "Precision: 0.959\n",
      "Recall:    1.000\n",
      "F1-score:  0.979\n",
      "\n",
      "ğŸ“Œ Dataset solo anomalie per supervised: (49643, 20)\n",
      "ğŸ“Œ Dataset bilanciato per supervised: (99286, 20)\n",
      "ğŸ’¾ Dataset salvati: completo + bilanciato.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ANALISI ANOMALIE + VALUTAZIONE SEMI-SUPERVISED + DATASET SUPERVISED\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# -------------------------------\n",
    "# 1ï¸âƒ£ Caricamento embeddings e anomalie\n",
    "# -------------------------------\n",
    "X_ensemble_latent = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_ensemble_latent.npy\")\n",
    "anomalies = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\anomalies.npy\")\n",
    "labels = np.load(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\labels.npy\", allow_pickle=True)\n",
    "\n",
    "print(f\"âœ… Embeddings ensemble: {X_ensemble_latent.shape}, Anomalie: {anomalies.shape}, Labels: {labels.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2ï¸âƒ£ Creazione DataFrame\n",
    "# -------------------------------\n",
    "latent_cols = [f'latent_{i}' for i in range(X_ensemble_latent.shape[1])]\n",
    "df_latent = pd.DataFrame(X_ensemble_latent, columns=latent_cols)\n",
    "df_latent['label_technique'] = labels\n",
    "df_latent['label_tactic'] = ['unknown'] * len(labels)\n",
    "df_latent['anomaly'] = anomalies\n",
    "df_latent['anomaly_flag'] = df_latent['anomaly'].map({1:0, -1:1})  # 1 = anomalia\n",
    "\n",
    "print(f\"âœ… Dataset pronto: {df_latent.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3ï¸âƒ£ Statistiche anomalie per label_technique\n",
    "# -------------------------------\n",
    "tech_anomalies = df_latent.groupby('label_technique')['anomaly_flag'].sum()\n",
    "tech_total = df_latent['label_technique'].value_counts()\n",
    "tech_pct = (tech_anomalies / tech_total * 100).round(2)\n",
    "\n",
    "anomaly_summary = pd.DataFrame({\n",
    "    'total_samples': tech_total,\n",
    "    'num_anomalies': tech_anomalies,\n",
    "    '%_anomalous': tech_pct\n",
    "}).sort_values('%_anomalous', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ“Š Percentuale anomalie per label_technique:\")\n",
    "display(anomaly_summary)\n",
    "\n",
    "# -------------------------------\n",
    "# 4ï¸âƒ£ Analisi approfondita anomalie\n",
    "# -------------------------------\n",
    "df_anomalies = df_latent[df_latent['anomaly_flag'] == 1]\n",
    "print(\"\\nğŸ“Œ Numero totale anomalie:\", len(df_anomalies))\n",
    "print(\"\\nğŸ“Œ Distribuzione anomalie per label_technique:\")\n",
    "display(df_anomalies['label_technique'].value_counts())\n",
    "\n",
    "# Feature latenti: media anomalie vs normali\n",
    "mean_features = df_latent.groupby('anomaly_flag')[latent_cols].mean()\n",
    "print(\"\\nğŸ“Š Media feature latenti (anomalia vs normale):\")\n",
    "display(mean_features)\n",
    "\n",
    "# -------------------------------\n",
    "# 5ï¸âƒ£ Valutazione semi-supervised\n",
    "# -------------------------------\n",
    "# Attacchi rari = tutte le label diverse da T1587 (dominante)\n",
    "rare_labels = df_latent['label_technique'].unique().tolist()\n",
    "if 'T1587' in rare_labels:\n",
    "    rare_labels.remove('T1587')\n",
    "\n",
    "y_true = df_latent['label_technique'].apply(lambda x: 1 if x in rare_labels else 0)\n",
    "y_pred = df_latent['anomaly_flag']\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nğŸ“Œ Metriche semi-supervised (Isolation Forest):\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6ï¸âƒ£ Dataset per supervised learning (opzionale)\n",
    "# -------------------------------\n",
    "df_supervised = df_latent[df_latent['anomaly_flag'] == 1].copy()\n",
    "print(\"\\nğŸ“Œ Dataset solo anomalie per supervised:\", df_supervised.shape)\n",
    "\n",
    "# Dataset bilanciato: anomalie + stesso numero di normali\n",
    "df_normals = df_latent[df_latent['anomaly_flag'] == 0].sample(n=len(df_supervised), random_state=42)\n",
    "df_balanced = pd.concat([df_supervised, df_normals]).reset_index(drop=True)\n",
    "print(\"ğŸ“Œ Dataset bilanciato per supervised:\", df_balanced.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 7ï¸âƒ£ Salvataggio dataset\n",
    "# -------------------------------\n",
    "df_latent.to_parquet(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_ensemble_latent_labeled.parquet\", index=False)\n",
    "df_balanced.to_parquet(r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\X_ensemble_latent_balanced.parquet\", index=False)\n",
    "print(\"ğŸ’¾ Dataset salvati: completo + bilanciato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121af827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeek-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
