{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c24f49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ZeekData22: 100%|██████████| 14/14 [02:35<00:00, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Tutti i file elaborati e salvati in: C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 1: Elaborazione file per file di ZeekData22 \n",
    "# ==========================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# Cartelle\n",
    "# ----------------------------\n",
    "input_dir = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\UWF-ZeekData22\"\n",
    "output_dir = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Lista file CSV/Parquet\n",
    "# ----------------------------\n",
    "all_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) \n",
    "             if f.endswith('.csv') or f.endswith('.parquet')]\n",
    "\n",
    "# ----------------------------\n",
    "# Funzione di pulizia e trasformazione\n",
    "# ----------------------------\n",
    "def clean_and_transform(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Pulizia valori numerici\n",
    "    for col in df.select_dtypes(include=['float64','int64']).columns:\n",
    "        df.loc[:, col] = df[col].fillna(df[col].mean())\n",
    "    \n",
    "    # Pulizia valori categorici\n",
    "    for col in df.select_dtypes(include=['object','category']).columns:\n",
    "        mode_val = df[col].mode()[0] if not df[col].mode().empty else 'unknown'\n",
    "        df.loc[:, col] = df[col].fillna(mode_val)\n",
    "    \n",
    "    # Pulizia label_binary\n",
    "    if 'label_binary' in df.columns:\n",
    "        df['label_binary'] = df['label_binary'].map({True:1, False:0, 'True':1, 'False':0, 1:1, 0:0})\n",
    "        df = df.dropna(subset=['label_binary'])\n",
    "        df['label_binary'] = df['label_binary'].astype(int)\n",
    "    \n",
    "    # Selezione feature numeriche (escludendo label)\n",
    "    num_features = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "    for col in ['label_binary','label_technique','label_tactic']:\n",
    "        if col in num_features:\n",
    "            num_features.remove(col)\n",
    "    \n",
    "    # Rimuovi feature a bassa varianza\n",
    "    variance = df[num_features].var()\n",
    "    selected_features = variance[variance > 0.01].index.tolist()\n",
    "    \n",
    "    # Winsorization + log-transform\n",
    "    for col in selected_features:\n",
    "        lower = df[col].quantile(0.01)\n",
    "        upper = df[col].quantile(0.99)\n",
    "        df[col] = np.clip(df[col], lower, upper)\n",
    "        min_val = df[col].min()\n",
    "        offset = abs(min_val)+1e-6 if min_val <= 0 else 0\n",
    "        df[col] = np.log1p(df[col] + offset)\n",
    "        df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Rimozione eventuali NaN residui\n",
    "    df = df.dropna(subset=selected_features)\n",
    "    \n",
    "    # A questo punto il file è pulito e trasformato, **senza bilanciamento**\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# Elaborazione file per file\n",
    "# ----------------------------\n",
    "for file_path in tqdm(all_files, desc=\"Processing ZeekData22\"):\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            df = pd.read_parquet(file_path)\n",
    "        \n",
    "        df_clean = clean_and_transform(df)\n",
    "        \n",
    "        base_name = os.path.basename(file_path)\n",
    "        output_file = os.path.join(output_dir, f\"processed_{base_name}.parquet\")\n",
    "        df_clean.to_parquet(output_file, index=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Errore con file {file_path}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Tutti i file elaborati e salvati in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585d1eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dataset caricato: 20607218 righe, 37 colonne\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colonne disponibili</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resp_pkts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig_ip_bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>local_resp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missed_bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>protocol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>conn_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dest_ip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>orig_pkts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>community_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resp_ip_bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dest_port</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>orig_bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>local_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>resp_bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>uid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>src_port</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>src_ip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mitre_attack_tactics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>proto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dest_ip_zeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dest_port_zeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>src_port_zeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>src_ip_zeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>label_tactic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-12-12 - 2021-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-12-19 - 2021-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-12-26 - 2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-01-02 - 2022-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2022-01-09 - 2022-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-01-16 - 2022-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-02-06 - 2022-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022-02-13 - 2022-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Colonne disponibili\n",
       "0                 resp_pkts\n",
       "1                   service\n",
       "2             orig_ip_bytes\n",
       "3                local_resp\n",
       "4              missed_bytes\n",
       "5                  protocol\n",
       "6                  duration\n",
       "7                conn_state\n",
       "8                   dest_ip\n",
       "9                 orig_pkts\n",
       "10             community_id\n",
       "11            resp_ip_bytes\n",
       "12                dest_port\n",
       "13               orig_bytes\n",
       "14               local_orig\n",
       "15                 datetime\n",
       "16                  history\n",
       "17               resp_bytes\n",
       "18                      uid\n",
       "19                 src_port\n",
       "20                       ts\n",
       "21                   src_ip\n",
       "22     mitre_attack_tactics\n",
       "23                    proto\n",
       "24             dest_ip_zeek\n",
       "25           dest_port_zeek\n",
       "26            src_port_zeek\n",
       "27              src_ip_zeek\n",
       "28             label_tactic\n",
       "29  2021-12-12 - 2021-12-19\n",
       "30  2021-12-19 - 2021-12-26\n",
       "31  2021-12-26 - 2022-01-02\n",
       "32  2022-01-02 - 2022-01-09\n",
       "33  2022-01-09 - 2022-01-16\n",
       "34  2022-01-16 - 2022-01-23\n",
       "35  2022-02-06 - 2022-02-13\n",
       "36  2022-02-13 - 2022-02-20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tattica</th>\n",
       "      <th>Conteggio</th>\n",
       "      <th>Percentuale (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>9281600</td>\n",
       "      <td>45.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reconnaissance</td>\n",
       "      <td>9278723</td>\n",
       "      <td>45.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discovery</td>\n",
       "      <td>2087</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credential Access</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Privilege Escalation</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Exfiltration</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lateral Movement</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Resource Development</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Defense Evasion</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Initial Access</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Persistence</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dt_first_record</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dt_last_record</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dt_week_end</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dt_week_start</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_record_count</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tattica  Conteggio  Percentuale (%)\n",
       "0                   none    9281600            45.04\n",
       "1         Reconnaissance    9278723            45.03\n",
       "2              Discovery       2087             0.01\n",
       "3      Credential Access         32             0.00\n",
       "4   Privilege Escalation         14             0.00\n",
       "5           Exfiltration          8             0.00\n",
       "6       Lateral Movement          5             0.00\n",
       "7   Resource Development          4             0.00\n",
       "8        Defense Evasion          2             0.00\n",
       "9         Initial Access          2             0.00\n",
       "10           Persistence          2             0.00\n",
       "11       dt_first_record          1             0.00\n",
       "12        dt_last_record          1             0.00\n",
       "13           dt_week_end          1             0.00\n",
       "14         dt_week_start          1             0.00\n",
       "15    total_record_count          1             0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 2: Visualizzazione colonne ZeekData22 \n",
    "# ==========================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Cartella dei file già processati\n",
    "processed_dir = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\"\n",
    "processed_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.endswith('.parquet')]\n",
    "\n",
    "# Caricamento in un unico DataFrame (attenzione, può essere grande!)\n",
    "dfs = []\n",
    "for file in processed_files:\n",
    "    dfs.append(pd.read_parquet(file))\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"📊 Dataset caricato: {len(data)} righe, {data.shape[1]} colonne\\n\")\n",
    "\n",
    "# ==============================\n",
    "# 1️⃣ Elenco colonne presenti\n",
    "# ==============================\n",
    "columns_df = pd.DataFrame({'Colonne disponibili': data.columns.tolist()})\n",
    "display(columns_df)\n",
    "\n",
    "# ==============================\n",
    "# 2️⃣ Distribuzione delle tattiche\n",
    "# ==============================\n",
    "# Controlliamo che la colonna esista\n",
    "if 'label_tactic' in data.columns:\n",
    "    tactic_counts = data['label_tactic'].value_counts().reset_index()\n",
    "    tactic_counts.columns = ['Tattica', 'Conteggio']\n",
    "    tactic_counts['Percentuale (%)'] = (tactic_counts['Conteggio'] / len(data) * 100).round(2)\n",
    "    display(tactic_counts)\n",
    "else:\n",
    "    print(\"⚠️ Colonna 'label_tactic' non presente nel dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a468ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ZeekDataFall22: 100%|██████████| 16/16 [00:02<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 ZeekDataFall22 caricato: 700395 righe, 38 colonne\n",
      "\n",
      "✅ Colonne comuni: 27\n",
      "❌ Solo in ZeekData22: 10\n",
      "❌ Solo in ZeekDataFall22: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solo in ZeekData22</th>\n",
       "      <th>Solo in ZeekDataFall22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-09 - 2022-01-16</td>\n",
       "      <td>2022-08-28 - 2022-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-16 - 2022-01-23</td>\n",
       "      <td>2022-09-04 - 2022-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-06 - 2022-02-13</td>\n",
       "      <td>2022-09-11 - 2022-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-13 - 2022-02-20</td>\n",
       "      <td>2022-09-18 - 2022-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dest_ip</td>\n",
       "      <td>2022-09-25 - 2022-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dest_port</td>\n",
       "      <td>2022-10-02 - 2022-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mitre_attack_tactics</td>\n",
       "      <td>2022-10-09 - 2022-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>protocol</td>\n",
       "      <td>2022-10-16 - 2022-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>src_ip</td>\n",
       "      <td>2022-10-23 - 2022-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>src_port</td>\n",
       "      <td>label_binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>label_technique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Solo in ZeekData22   Solo in ZeekDataFall22\n",
       "0   2022-01-09 - 2022-01-16  2022-08-28 - 2022-09-04\n",
       "1   2022-01-16 - 2022-01-23  2022-09-04 - 2022-09-11\n",
       "2   2022-02-06 - 2022-02-13  2022-09-11 - 2022-09-18\n",
       "3   2022-02-13 - 2022-02-20  2022-09-18 - 2022-09-25\n",
       "4                   dest_ip  2022-09-25 - 2022-10-02\n",
       "5                 dest_port  2022-10-02 - 2022-10-09\n",
       "6      mitre_attack_tactics  2022-10-09 - 2022-10-16\n",
       "7                  protocol  2022-10-16 - 2022-10-23\n",
       "8                    src_ip  2022-10-23 - 2022-10-30\n",
       "9                  src_port             label_binary\n",
       "10                      NaN          label_technique"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Colonne con contenuto simile ma nome diverso:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colonna ZeekData22</th>\n",
       "      <th>Colonna ZeekDataFall22</th>\n",
       "      <th>Somiglianza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-09 - 2022-01-16</td>\n",
       "      <td>2022-08-28 - 2022-09-04</td>\n",
       "      <td>Categorica - Overlap: 100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-09 - 2022-01-16</td>\n",
       "      <td>2022-09-04 - 2022-09-11</td>\n",
       "      <td>Categorica - Overlap: 100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-09 - 2022-01-16</td>\n",
       "      <td>2022-09-11 - 2022-09-18</td>\n",
       "      <td>Categorica - Overlap: 100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-09 - 2022-01-16</td>\n",
       "      <td>2022-09-18 - 2022-09-25</td>\n",
       "      <td>Categorica - Overlap: 100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-09 - 2022-01-16</td>\n",
       "      <td>2022-09-25 - 2022-10-02</td>\n",
       "      <td>Categorica - Overlap: 100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>src_ip</td>\n",
       "      <td>2022-10-02 - 2022-10-09</td>\n",
       "      <td>Categorica - Overlap: 90.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>src_ip</td>\n",
       "      <td>2022-10-09 - 2022-10-16</td>\n",
       "      <td>Categorica - Overlap: 90.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>src_ip</td>\n",
       "      <td>2022-10-16 - 2022-10-23</td>\n",
       "      <td>Categorica - Overlap: 90.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>src_ip</td>\n",
       "      <td>2022-10-23 - 2022-10-30</td>\n",
       "      <td>Categorica - Overlap: 90.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>src_ip</td>\n",
       "      <td>label_binary</td>\n",
       "      <td>Categorica - Overlap: 90.19%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Colonna ZeekData22   Colonna ZeekDataFall22  \\\n",
       "0   2022-01-09 - 2022-01-16  2022-08-28 - 2022-09-04   \n",
       "1   2022-01-09 - 2022-01-16  2022-09-04 - 2022-09-11   \n",
       "2   2022-01-09 - 2022-01-16  2022-09-11 - 2022-09-18   \n",
       "3   2022-01-09 - 2022-01-16  2022-09-18 - 2022-09-25   \n",
       "4   2022-01-09 - 2022-01-16  2022-09-25 - 2022-10-02   \n",
       "..                      ...                      ...   \n",
       "75                   src_ip  2022-10-02 - 2022-10-09   \n",
       "76                   src_ip  2022-10-09 - 2022-10-16   \n",
       "77                   src_ip  2022-10-16 - 2022-10-23   \n",
       "78                   src_ip  2022-10-23 - 2022-10-30   \n",
       "79                   src_ip             label_binary   \n",
       "\n",
       "                      Somiglianza  \n",
       "0   Categorica - Overlap: 100.00%  \n",
       "1   Categorica - Overlap: 100.00%  \n",
       "2   Categorica - Overlap: 100.00%  \n",
       "3   Categorica - Overlap: 100.00%  \n",
       "4   Categorica - Overlap: 100.00%  \n",
       "..                            ...  \n",
       "75   Categorica - Overlap: 90.19%  \n",
       "76   Categorica - Overlap: 90.19%  \n",
       "77   Categorica - Overlap: 90.19%  \n",
       "78   Categorica - Overlap: 90.19%  \n",
       "79   Categorica - Overlap: 90.19%  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 3: Confronto colonne ZeekData22 vs ZeekDataFall22\n",
    "# ==========================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Percorso dataset Fall22 ===\n",
    "folder_fall22 = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\UWF-ZeekDataFall22\"\n",
    "\n",
    "# === Caricamento (come già fatto per ZeekData22) ===\n",
    "all_files_fall22 = [os.path.join(folder_fall22, f) \n",
    "                    for f in os.listdir(folder_fall22) \n",
    "                    if f.endswith('.csv') or f.endswith('.parquet')]\n",
    "\n",
    "dfs_fall22 = []\n",
    "for f in tqdm(all_files_fall22, desc=\"Loading ZeekDataFall22\"):\n",
    "    if f.endswith('.csv'):\n",
    "        dfs_fall22.append(pd.read_csv(f))\n",
    "    else:\n",
    "        dfs_fall22.append(pd.read_parquet(f))\n",
    "\n",
    "data_fall22 = pd.concat(dfs_fall22, ignore_index=True)\n",
    "print(f\"\\n📊 ZeekDataFall22 caricato: {len(data_fall22)} righe, {data_fall22.shape[1]} colonne\\n\")\n",
    "\n",
    "# === 1️⃣ Confronto diretto nomi colonne ===\n",
    "cols_22 = set(data.columns)\n",
    "cols_fall22 = set(data_fall22.columns)\n",
    "\n",
    "common_cols = sorted(list(cols_22.intersection(cols_fall22)))\n",
    "only_in_22 = sorted(list(cols_22 - cols_fall22))\n",
    "only_in_fall22 = sorted(list(cols_fall22 - cols_22))\n",
    "\n",
    "print(\"✅ Colonne comuni:\", len(common_cols))\n",
    "print(\"❌ Solo in ZeekData22:\", len(only_in_22))\n",
    "print(\"❌ Solo in ZeekDataFall22:\", len(only_in_fall22))\n",
    "\n",
    "# Tabella riepilogativa\n",
    "diff_table = pd.DataFrame({\n",
    "    \"Solo in ZeekData22\": pd.Series(only_in_22),\n",
    "    \"Solo in ZeekDataFall22\": pd.Series(only_in_fall22)\n",
    "})\n",
    "display(diff_table)\n",
    "\n",
    "# === 2️⃣ Analisi somiglianza colonne con nome diverso ===\n",
    "# Per evitare rallentamenti, usa solo un campione casuale\n",
    "sample_22 = data.sample(n=min(10000, len(data)), random_state=42)\n",
    "sample_fall22 = data_fall22.sample(n=min(10000, len(data_fall22)), random_state=42)\n",
    "\n",
    "similarity_report = []\n",
    "\n",
    "for col_22 in only_in_22:\n",
    "    for col_fall in only_in_fall22:\n",
    "        try:\n",
    "            # se entrambe sono numeriche\n",
    "            if pd.api.types.is_numeric_dtype(sample_22[col_22]) and pd.api.types.is_numeric_dtype(sample_fall22[col_fall]):\n",
    "                corr = sample_22[col_22].corr(sample_fall22[col_fall])\n",
    "                if corr > 0.95:\n",
    "                    similarity_report.append((col_22, col_fall, f\"Numerica - Corr: {corr:.3f}\"))\n",
    "            # se entrambe sono stringhe\n",
    "            elif pd.api.types.is_object_dtype(sample_22[col_22]) and pd.api.types.is_object_dtype(sample_fall22[col_fall]):\n",
    "                overlap = (sample_22[col_22].isin(sample_fall22[col_fall])).mean()\n",
    "                if overlap > 0.9:\n",
    "                    similarity_report.append((col_22, col_fall, f\"Categorica - Overlap: {overlap:.2%}\"))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "# === 3️⃣ Output somiglianze trovate ===\n",
    "if similarity_report:\n",
    "    print(\"\\n🔍 Colonne con contenuto simile ma nome diverso:\")\n",
    "    sim_df = pd.DataFrame(similarity_report, columns=[\"Colonna ZeekData22\", \"Colonna ZeekDataFall22\", \"Somiglianza\"])\n",
    "    display(sim_df)\n",
    "else:\n",
    "    print(\"\\nℹ️ Nessuna colonna con contenuto simile trovata tra i nomi diversi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering ZeekData22:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering ZeekData22: 100%|██████████| 18/18 [01:33<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Totale righe iniziali: 41548181\n",
      "⚠️ Benigni rimossi: 9281600 (22.34%)\n",
      "✅ Righe rimanenti dopo filtraggio: 32266581\n",
      "💾 Blocchi filtrati salvati in: C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\filtered_chunks\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 246. MiB for an array with shape (1, 32266581) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Ora carica tutti i chunk filtrati (molto più leggeri) in un unico DataFrame\u001b[39;00m\n\u001b[32m     49\u001b[39m dfs = [pd.read_parquet(os.path.join(temp_dir, f)) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(temp_dir) \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.parquet\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m dfs\n\u001b[32m     52\u001b[39m gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:393\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    378\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    380\u001b[39m op = _Concatenator(\n\u001b[32m    381\u001b[39m     objs,\n\u001b[32m    382\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     sort=sort,\n\u001b[32m    391\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    676\u001b[39m             indexers[ax] = obj_labels.get_indexer(new_labels)\n\u001b[32m    678\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m new_data = \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[32m    684\u001b[39m     new_data._consolidate_inplace()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:189\u001b[39m, in \u001b[36mconcatenate_managers\u001b[39m\u001b[34m(mgrs_indexers, axes, concat_axis, copy)\u001b[39m\n\u001b[32m    187\u001b[39m     fastpath = blk.values.dtype == values.dtype\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     values = \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     fastpath = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:486\u001b[39m, in \u001b[36m_concatenate_join_units\u001b[39m\u001b[34m(join_units, copy)\u001b[39m\n\u001b[32m    483\u001b[39m     concat_values = ensure_block_shape(concat_values, \u001b[32m2\u001b[39m)\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     concat_values = \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m empty_dtype != empty_dtype_future:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m empty_dtype == concat_values.dtype:\n\u001b[32m    490\u001b[39m         \u001b[38;5;66;03m# GH#39122, GH#40893\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\core\\dtypes\\concat.py:78\u001b[39m, in \u001b[36mconcat_compat\u001b[39m\u001b[34m(to_concat, axis, ea_compat_axis)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np.ndarray):\n\u001b[32m     77\u001b[39m     to_concat_arrs = cast(\u001b[33m\"\u001b[39m\u001b[33mSequence[np.ndarray]\u001b[39m\u001b[33m\"\u001b[39m, to_concat)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_arrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m to_concat_eas = cast(\u001b[33m\"\u001b[39m\u001b[33mSequence[ExtensionArray]\u001b[39m\u001b[33m\"\u001b[39m, to_concat)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 246. MiB for an array with shape (1, 32266581) and data type object"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 4: Analisi ZeekData22 (pulizia, varianza e confronto con ZeekDataFall22)\n",
    "# ==========================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# ================================\n",
    "# Step 1️⃣ + 2️⃣ - Caricamento, filtraggio e salvataggio progressivo (no concat in RAM)\n",
    "# ================================\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "processed_dir = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\"\n",
    "temp_dir = os.path.join(processed_dir, \"filtered_chunks\")\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "processed_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.endswith('.parquet')]\n",
    "\n",
    "total_rows, benign_rows, kept_rows = 0, 0, 0\n",
    "\n",
    "for i, file in enumerate(tqdm(processed_files, desc=\"Filtering ZeekData22\")):\n",
    "    df = pd.read_parquet(file)\n",
    "    total_rows += len(df)\n",
    "\n",
    "    if 'label_tactic' in df.columns:\n",
    "        benign_count = (df['label_tactic'] == 'none').sum()\n",
    "        benign_rows += benign_count\n",
    "        df = df[df['label_tactic'] != 'none']\n",
    "    \n",
    "    kept_rows += len(df)\n",
    "    # Salva ogni blocco filtrato come Parquet temporaneo\n",
    "    chunk_path = os.path.join(temp_dir, f\"filtered_chunk_{i}.parquet\")\n",
    "    df.to_parquet(chunk_path, index=False)\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n📊 Totale righe iniziali: {total_rows}\")\n",
    "print(f\"⚠️ Benigni rimossi: {benign_rows} ({benign_rows/total_rows*100:.2f}%)\")\n",
    "print(f\"✅ Righe rimanenti dopo filtraggio: {kept_rows}\")\n",
    "print(f\"💾 Blocchi filtrati salvati in: {temp_dir}\")\n",
    "\n",
    "# Ora carica tutti i chunk filtrati (molto più leggeri) in un unico DataFrame\n",
    "dfs = [pd.read_parquet(os.path.join(temp_dir, f)) for f in os.listdir(temp_dir) if f.endswith('.parquet')]\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "del dfs\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n📊 Dataset finale caricato: {len(data)} righe totali (post-filtraggio).\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 3️⃣ - Controllo valori nulli\n",
    "# ================================\n",
    "null_counts = data.isna().sum()\n",
    "null_cols = null_counts[null_counts > 0]\n",
    "\n",
    "if len(null_cols) == 0:\n",
    "    print(\"\\n✅ Nessun valore nullo rilevato.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Colonne con valori nulli:\")\n",
    "    display(null_cols)\n",
    "\n",
    "# ================================\n",
    "# Step 4️⃣ - Selezione feature numeriche e categoriali\n",
    "# ================================\n",
    "num_features = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_features = data.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "print(\"\\n🔹 Feature numeriche:\", num_features)\n",
    "print(\"\\n🔹 Feature categoriali:\", cat_features)\n",
    "\n",
    "# ================================\n",
    "# Step 5️⃣ - Calcolo varianza per feature numeriche\n",
    "# ================================\n",
    "variance = data[num_features].var().sort_values(ascending=False)\n",
    "var_table = pd.DataFrame({\n",
    "    'Feature': variance.index,\n",
    "    'Varianza': variance.values,\n",
    "    'Significativa (>0.01)': ['✅' if v > 0.01 else '❌' for v in variance.values]\n",
    "})\n",
    "\n",
    "print(\"\\n📊 Tabella varianza (ZeekData22):\")\n",
    "display(var_table)\n",
    "\n",
    "# Selezione feature significative\n",
    "selected_features = variance[variance > 0.01].index.tolist()\n",
    "print(f\"\\n✅ Feature con varianza significativa ({len(selected_features)}): {selected_features}\")\n",
    "\n",
    "# Salvataggio\n",
    "variance22_path = os.path.join(processed_dir, \"feature_variance_zeekdata22.csv\")\n",
    "var_table.to_csv(variance22_path, index=False)\n",
    "print(f\"💾 Tabella varianza ZeekData22 salvata in: {variance22_path}\")\n",
    "\n",
    "# ================================\n",
    "# Step 6️⃣ - Analisi outlier e trasformazione\n",
    "# ================================\n",
    "outlier_summary = {}\n",
    "for col in tqdm(selected_features, desc=\"Analisi outlier\"):\n",
    "    Q1, Q3 = data[col].quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "    outlier_summary[col] = ((data[col]<lower) | (data[col]>upper)).sum()\n",
    "\n",
    "print(\"\\n⚠️ Numero di outlier per feature:\")\n",
    "display(pd.Series(outlier_summary))\n",
    "\n",
    "# Trasformazioni\n",
    "print(\"\\n🏗️ Applicazione Winsorization + Log Transform...\")\n",
    "for col in tqdm(selected_features, desc=\"Trasformazione\"):\n",
    "    lower = data[col].quantile(0.01)\n",
    "    upper = data[col].quantile(0.99)\n",
    "    data[col] = np.clip(data[col], lower, upper)\n",
    "    min_val = data[col].min()\n",
    "    offset = abs(min_val)+1e-6 if min_val <= 0 else 0\n",
    "    data[col] = np.log1p(data[col] + offset)\n",
    "    data[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "data = data.dropna(subset=selected_features)\n",
    "print(\"✅ Dataset pulito e trasformato.\")\n",
    "\n",
    "# ================================\n",
    "# Step 7️⃣ - Confronto con varianza ZeekDataFall22\n",
    "# ================================\n",
    "fall22_var_path = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\feature_variance_fall22.csv\"\n",
    "if os.path.exists(fall22_var_path):\n",
    "    var_fall22 = pd.read_csv(fall22_var_path)\n",
    "    var22 = pd.read_csv(variance22_path)\n",
    "\n",
    "    merged_var = pd.merge(var22, var_fall22, on='Feature', how='outer', suffixes=('_ZeekData22','_ZeekDataFall22'))\n",
    "    merged_var.fillna(0, inplace=True)\n",
    "\n",
    "    print(\"\\n📊 Confronto varianza tra ZeekData22 e ZeekDataFall22:\")\n",
    "    display(merged_var.head(20))\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.scatterplot(data=merged_var, x='Varianza_ZeekDataFall22', y='Varianza_ZeekData22')\n",
    "    plt.title(\"📈 Confronto varianza feature tra ZeekDataFall22 e ZeekData22\")\n",
    "    plt.xlabel(\"Varianza ZeekDataFall22\")\n",
    "    plt.ylabel(\"Varianza ZeekData22\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n⚠️ File feature_variance_fall22.csv non trovato, confronto non eseguito.\")\n",
    "\n",
    "# ================================\n",
    "# Step 8️⃣ - Statistiche descrittive post trasformazione\n",
    "# ================================\n",
    "print(\"\\n📄 Statistiche descrittive (post trasformazione):\")\n",
    "display(data[selected_features].describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7517f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering ZeekData22: 100%|██████████| 14/14 [00:51<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Totale righe iniziali: 20607218\n",
      "Benigni rimossi: 9281600 (45.04%)\n",
      "Righe rimanenti dopo filtraggio: 11325618\n",
      "\n",
      "Dataset finale caricato: 11325618 righe\n",
      "\n",
      "Feature numeriche selezionate (11): ['ts', 'dest_port_zeek', 'src_port_zeek', 'resp_ip_bytes', 'orig_ip_bytes', 'resp_bytes', 'orig_bytes', 'resp_pkts', 'orig_pkts', 'missed_bytes', 'duration']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Winsorization + LogTransform: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset ZeekData22 pronto per test salvato in: C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\ZeekData22_test_ready.parquet\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 5: Preprocessing robusto ZeekData22 per test encoder Fall22\n",
    "# ==========================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# --------------------------\n",
    "# Percorsi\n",
    "# --------------------------\n",
    "processed_dir = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\"\n",
    "temp_dir = os.path.join(processed_dir, \"filtered_chunks\")\n",
    "fall22_var_path = os.path.join(processed_dir, \"feature_variance_fall22.csv\")\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# --------------------------\n",
    "# Step 1: Caricamento e filtraggio benigni in chunk\n",
    "# --------------------------\n",
    "processed_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.endswith('.parquet')]\n",
    "kept_rows, total_rows, benign_rows = 0, 0, 0\n",
    "\n",
    "for i, file in enumerate(tqdm(processed_files, desc=\"Filtering ZeekData22\")):\n",
    "    df = pd.read_parquet(file)\n",
    "    total_rows += len(df)\n",
    "\n",
    "    if 'label_tactic' in df.columns:\n",
    "        benign_count = (df['label_tactic'] == 'none').sum()\n",
    "        benign_rows += benign_count\n",
    "        df = df[df['label_tactic'] != 'none']\n",
    "    \n",
    "    kept_rows += len(df)\n",
    "    # Salva chunk filtrato\n",
    "    chunk_path = os.path.join(temp_dir, f\"filtered_chunk_{i}.parquet\")\n",
    "    df.to_parquet(chunk_path, index=False)\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\nTotale righe iniziali: {total_rows}\")\n",
    "print(f\"Benigni rimossi: {benign_rows} ({benign_rows/total_rows*100:.2f}%)\")\n",
    "print(f\"Righe rimanenti dopo filtraggio: {kept_rows}\")\n",
    "\n",
    "# --------------------------\n",
    "# Step 2: Caricamento chunk filtrati in DataFrame unico (più leggero)\n",
    "# --------------------------\n",
    "dfs = [pd.read_parquet(os.path.join(temp_dir, f)) for f in os.listdir(temp_dir) if f.endswith('.parquet')]\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "del dfs\n",
    "gc.collect()\n",
    "print(f\"\\nDataset finale caricato: {len(data)} righe\")\n",
    "\n",
    "# --------------------------\n",
    "# Step 3: Selezione feature numeriche e allineamento con Fall22\n",
    "# --------------------------\n",
    "num_features = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "if os.path.exists(fall22_var_path):\n",
    "    var_fall22 = pd.read_csv(fall22_var_path)\n",
    "    fall22_features = var_fall22['Feature'].tolist()\n",
    "    # Conserva solo le feature numeriche usate dall'encoder Fall22\n",
    "    selected_features = [f for f in fall22_features if f in num_features]\n",
    "else:\n",
    "    selected_features = num_features  # fallback\n",
    "print(f\"\\nFeature numeriche selezionate ({len(selected_features)}): {selected_features}\")\n",
    "\n",
    "# --------------------------\n",
    "# Step 4: Gestione outlier e trasformazione robusta\n",
    "# --------------------------\n",
    "for col in tqdm(selected_features, desc=\"Winsorization + LogTransform\"):\n",
    "    # Winsorization: clip tra 1° e 99° percentile\n",
    "    lower = data[col].quantile(0.01)\n",
    "    upper = data[col].quantile(0.99)\n",
    "    data[col] = np.clip(data[col], lower, upper)\n",
    "    \n",
    "    # Log-transform robusto\n",
    "    data[col] = np.log1p(data[col].clip(lower=0))\n",
    "\n",
    "# --------------------------\n",
    "# Step 5: Gestione NaN senza droppare righe\n",
    "# --------------------------\n",
    "data[selected_features] = data[selected_features].fillna(0)\n",
    "\n",
    "# --------------------------\n",
    "# Step 6: Salvataggio dataset pronto per test\n",
    "# --------------------------\n",
    "test_path = os.path.join(processed_dir, \"ZeekData22_test_ready.parquet\")\n",
    "data[selected_features].to_parquet(test_path, index=False)\n",
    "print(f\"\\n✅ Dataset ZeekData22 pronto per test salvato in: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "558ae325",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\maria\\\\Desktop\\\\Zeek_ML\\\\processed_zeekdata22\\\\categorical_features_zeekdata22.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m catfall_path = os.path.join(processed_dir, \u001b[33m\"\u001b[39m\u001b[33mcategorical_features_zeekdatafall22.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Caricamento feature categoriali\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m cat22 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat22_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m catfall = pd.read_parquet(catfall_path)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Analisi colonne\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\io\\parquet.py:670\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    667\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    668\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\io\\parquet.py:265\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    263\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    272\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    273\u001b[39m         path_or_handle,\n\u001b[32m    274\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m         **kwargs,\n\u001b[32m    278\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\io\\parquet.py:139\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    129\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    131\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    143\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    863\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    864\u001b[39m             handle,\n\u001b[32m    865\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    868\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    869\u001b[39m         )\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m872\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n\u001b[32m    873\u001b[39m     handles.append(handle)\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\maria\\\\Desktop\\\\Zeek_ML\\\\processed_zeekdata22\\\\categorical_features_zeekdata22.parquet'"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 6b: Confronto avanzato feature categoriali ZeekData22 vs ZeekDataFall22\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "processed_dir = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\"\n",
    "output_dir = os.path.join(processed_dir, \"reports\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Percorsi\n",
    "cat22_path = os.path.join(processed_dir, \"categorical_features_zeekdata22.parquet\")\n",
    "catfall_path = os.path.join(processed_dir, \"categorical_features_zeekdatafall22.parquet\")\n",
    "\n",
    "# Caricamento feature categoriali\n",
    "cat22 = pd.read_parquet(cat22_path)\n",
    "catfall = pd.read_parquet(catfall_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Analisi colonne\n",
    "# -----------------------------\n",
    "common_cols = [c for c in cat22.columns if c in catfall.columns]\n",
    "only_22 = [c for c in cat22.columns if c not in catfall.columns]\n",
    "only_fall = [c for c in catfall.columns if c not in cat22.columns]\n",
    "\n",
    "print(f\"🔹 Colonne comuni: {len(common_cols)}\")\n",
    "print(f\"🔹 Colonne solo ZeekData22: {len(only_22)} -> {only_22}\")\n",
    "print(f\"🔹 Colonne solo ZeekDataFall22: {len(only_fall)} -> {only_fall}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Report valori unici colonne comuni\n",
    "# -----------------------------\n",
    "report_rows = []\n",
    "\n",
    "for col in common_cols:\n",
    "    vals_22 = set(cat22[col].dropna().unique())\n",
    "    vals_fall = set(catfall[col].dropna().unique())\n",
    "    only_in_22 = vals_22 - vals_fall\n",
    "    only_in_fall = vals_fall - vals_22\n",
    "    report_rows.append({\n",
    "        'Feature': col,\n",
    "        'Unique_in_ZeekData22': len(vals_22),\n",
    "        'Unique_in_ZeekDataFall22': len(vals_fall),\n",
    "        'Only_in_22': list(only_in_22),\n",
    "        'Only_in_Fall': list(only_in_fall)\n",
    "    })\n",
    "\n",
    "report_df = pd.DataFrame(report_rows)\n",
    "report_csv_path = os.path.join(output_dir, \"categorical_features_comparison_report.csv\")\n",
    "report_df.to_csv(report_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n💾 Report valori unici salvato in: {report_csv_path}\")\n",
    "print(\"✅ Confronto completato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e58ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Righe dopo filtraggio classi target (3): 9280814\n",
      "\n",
      "📊 Distribuzione classi target:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_tactic_reduced</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reconnaissance</th>\n",
       "      <td>9278723</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discovery</th>\n",
       "      <td>2087</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Development</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Count  Percent (%)\n",
       "label_tactic_reduced                      \n",
       "Reconnaissance        9278723        99.98\n",
       "Discovery                2087         0.02\n",
       "Resource Development        4         0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Feature numeriche selezionate (11): ['ts', 'dest_port_zeek', 'src_port_zeek', 'resp_ip_bytes', 'orig_ip_bytes', 'resp_bytes', 'orig_bytes', 'resp_pkts', 'orig_pkts', 'missed_bytes', 'duration']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Winsorization + LogTransform: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset ZeekData22 pronto per test con classi target salvato in: C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\ZeekData22_test_ready_classes.parquet\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# BLOCCO 6: Preprocessing numerico + filtraggio classi per test\n",
    "# ================================\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------\n",
    "# Classe target da mantenere\n",
    "# --------------------------\n",
    "target_classes = ['Resource Development', 'Reconnaissance', 'Discovery']\n",
    "\n",
    "# Filtra solo le righe con classi target\n",
    "if 'label_tactic' in data.columns:\n",
    "    # Manteniamo anche la categoria \"Other\" per eventuali righe residue\n",
    "    data['label_tactic_reduced'] = data['label_tactic'].where(\n",
    "        data['label_tactic'].isin(target_classes), other='Other'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ Righe dopo filtraggio classi target ({len(target_classes)}): {len(data)}\")\n",
    "\n",
    "    # --------------------------\n",
    "    # Tabella distribuzione classi\n",
    "    # --------------------------\n",
    "    class_counts = data['label_tactic_reduced'].value_counts()\n",
    "    class_percent = (class_counts / len(data) * 100).round(2)\n",
    "    class_table = pd.DataFrame({\n",
    "        'Count': class_counts,\n",
    "        'Percent (%)': class_percent\n",
    "    })\n",
    "    print(\"\\n📊 Distribuzione classi target:\")\n",
    "    display(class_table)\n",
    "\n",
    "# --------------------------\n",
    "# Feature numeriche da usare\n",
    "# --------------------------\n",
    "num_features = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "if os.path.exists(fall22_var_path):\n",
    "    var_fall22 = pd.read_csv(fall22_var_path)\n",
    "    fall22_features = var_fall22['Feature'].tolist()\n",
    "    selected_features = [f for f in fall22_features if f in num_features]\n",
    "else:\n",
    "    selected_features = num_features\n",
    "print(f\"\\n🔹 Feature numeriche selezionate ({len(selected_features)}): {selected_features}\")\n",
    "\n",
    "# --------------------------\n",
    "# Winsorization + LogTransform robusto\n",
    "# --------------------------\n",
    "for col in tqdm(selected_features, desc=\"Winsorization + LogTransform\"):\n",
    "    lower = data[col].quantile(0.01)\n",
    "    upper = data[col].quantile(0.99)\n",
    "    data[col] = np.clip(data[col], lower, upper)\n",
    "    data[col] = np.log1p(data[col].clip(lower=0))\n",
    "\n",
    "# --------------------------\n",
    "# Gestione NaN senza droppare righe\n",
    "# --------------------------\n",
    "data[selected_features] = data[selected_features].fillna(0)\n",
    "\n",
    "# --------------------------\n",
    "# Salvataggio dataset pronto per test\n",
    "# --------------------------\n",
    "test_path = os.path.join(processed_dir, \"ZeekData22_test_ready_classes.parquet\")\n",
    "data[selected_features + ['label_tactic_reduced']].to_parquet(test_path, index=False)\n",
    "print(f\"\\n✅ Dataset ZeekData22 pronto per test con classi target salvato in: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ab80ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Righe dopo filtraggio Discovery + Reconnaissance: 9280810\n",
      "\n",
      "📊 Distribuzione originale delle classi:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_tactic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reconnaissance</th>\n",
       "      <td>9278723</td>\n",
       "      <td>99.977513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discovery</th>\n",
       "      <td>2087</td>\n",
       "      <td>0.022487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count  Percent (%)\n",
       "label_tactic                        \n",
       "Reconnaissance  9278723    99.977513\n",
       "Discovery          2087     0.022487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset bilanciato pronto: 4174 righe\n",
      "\n",
      "🔹 Feature numeriche selezionate (11): ['ts', 'dest_port_zeek', 'src_port_zeek', 'resp_ip_bytes', 'orig_ip_bytes', 'resp_bytes', 'orig_bytes', 'resp_pkts', 'orig_pkts', 'missed_bytes', 'duration']\n",
      "\n",
      "💾 Dataset bilanciato salvato in: C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\ZeekData22_test_ready_balanced.parquet\n",
      "\n",
      "📊 Distribuzione finale delle classi bilanciate:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_tactic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reconnaissance</th>\n",
       "      <td>2087</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discovery</th>\n",
       "      <td>2087</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Count  Percent (%)\n",
       "label_tactic                      \n",
       "Reconnaissance   2087         50.0\n",
       "Discovery        2087         50.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================\n",
    "# BLOCCO 7: Bilanciamento classi Discovery e Reconnaissance\n",
    "# ================================\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --------------------------\n",
    "# Filtra solo le due classi principali\n",
    "# --------------------------\n",
    "data_bal = data[data['label_tactic'].isin(['Reconnaissance', 'Discovery'])].copy()\n",
    "print(f\"\\n✅ Righe dopo filtraggio Discovery + Reconnaissance: {len(data_bal)}\")\n",
    "\n",
    "# --------------------------\n",
    "# Controllo distribuzione originale\n",
    "# --------------------------\n",
    "class_counts = data_bal['label_tactic'].value_counts()\n",
    "class_percent = data_bal['label_tactic'].value_counts(normalize=True) * 100\n",
    "dist_table = pd.DataFrame({'Count': class_counts, 'Percent (%)': class_percent})\n",
    "print(\"\\n📊 Distribuzione originale delle classi:\")\n",
    "display(dist_table)\n",
    "\n",
    "# --------------------------\n",
    "# Downsample della classe maggiore\n",
    "# --------------------------\n",
    "minority_class_size = class_counts.min()\n",
    "dfs_balanced = []\n",
    "\n",
    "for cls in ['Reconnaissance', 'Discovery']:\n",
    "    cls_df = data_bal[data_bal['label_tactic'] == cls]\n",
    "    if len(cls_df) > minority_class_size:\n",
    "        cls_df = resample(cls_df,\n",
    "                          replace=False,\n",
    "                          n_samples=minority_class_size,\n",
    "                          random_state=42)\n",
    "    dfs_balanced.append(cls_df)\n",
    "\n",
    "# --------------------------\n",
    "# Combina classi bilanciate\n",
    "# --------------------------\n",
    "data_balanced = pd.concat(dfs_balanced, ignore_index=True)\n",
    "data_balanced = data_balanced.sample(frac=1, random_state=42)  # shuffle\n",
    "print(f\"\\n✅ Dataset bilanciato pronto: {len(data_balanced)} righe\")\n",
    "\n",
    "# --------------------------\n",
    "# Feature numeriche da usare\n",
    "# --------------------------\n",
    "selected_features = [f for f in selected_features if f in data_balanced.columns]\n",
    "print(f\"\\n🔹 Feature numeriche selezionate ({len(selected_features)}): {selected_features}\")\n",
    "\n",
    "# --------------------------\n",
    "# Salvataggio dataset bilanciato pronto per test\n",
    "# --------------------------\n",
    "balanced_path = os.path.join(processed_dir, \"ZeekData22_test_ready_balanced.parquet\")\n",
    "data_balanced[selected_features + ['label_tactic']].to_parquet(balanced_path, index=False)\n",
    "print(f\"\\n💾 Dataset bilanciato salvato in: {balanced_path}\")\n",
    "\n",
    "# --------------------------\n",
    "# Distribuzione finale\n",
    "# --------------------------\n",
    "final_counts = data_balanced['label_tactic'].value_counts()\n",
    "final_percent = data_balanced['label_tactic'].value_counts(normalize=True) * 100\n",
    "final_table = pd.DataFrame({'Count': final_counts, 'Percent (%)': final_percent})\n",
    "print(\"\\n📊 Distribuzione finale delle classi bilanciate:\")\n",
    "display(final_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2a26d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test set caricato: 4174 righe, 11 feature\n",
      "✅ Feature test set allineate correttamente: (4174, 16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 28), found shape=(32, 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     59\u001b[39m X_test = X_test.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Generazione embeddings latenti\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m X_test_latent = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m latent_cols = [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlatent_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_test_latent.shape[\u001b[32m1\u001b[39m])]\n\u001b[32m     66\u001b[39m X_test_latent = pd.DataFrame(X_test_latent, columns=latent_cols)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim != dim:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    246\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mincompatible with the layer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    249\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    250\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 28), found shape=(32, 16)"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 7️⃣ - Generazione embeddings Test Set ZeekData22 (allineato Fall22)\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --------------------------\n",
    "# Percorsi\n",
    "# --------------------------\n",
    "encoder_path = \"model_data/encoder_best.keras\"\n",
    "scaler_path = \"model_data/scaler_latent.pkl\"\n",
    "fall22_var_path = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\feature_variance_fall22.csv\"\n",
    "test_path = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\\ZeekData22_test_ready_balanced.parquet\"\n",
    "output_dir = \"model_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --------------------------\n",
    "# Caricamento encoder, scaler e test set\n",
    "# --------------------------\n",
    "encoder = load_model(encoder_path)\n",
    "scaler_latent = joblib.load(scaler_path)\n",
    "data_test = pd.read_parquet(test_path)\n",
    "\n",
    "# Separazione feature/label\n",
    "X_test = data_test.drop(columns=['label_tactic'])\n",
    "y_test = data_test['label_tactic'].reset_index(drop=True)\n",
    "print(f\"✅ Test set caricato: {X_test.shape[0]} righe, {X_test.shape[1]} feature\")\n",
    "\n",
    "# --------------------------\n",
    "# Allineamento feature con Fall22\n",
    "# --------------------------\n",
    "fall22_features = pd.read_csv(fall22_var_path)['Feature'].tolist()\n",
    "\n",
    "# Rimuovi eventuali feature extra\n",
    "X_test = X_test[[f for f in fall22_features if f in X_test.columns]]\n",
    "\n",
    "# Aggiungi feature mancanti con 0\n",
    "for f in fall22_features:\n",
    "    if f not in X_test.columns:\n",
    "        X_test[f] = 0\n",
    "\n",
    "# Ordina colonne come nell'encoder Fall22\n",
    "X_test = X_test[fall22_features]\n",
    "print(f\"✅ Feature test set allineate correttamente: {X_test.shape}\")\n",
    "\n",
    "# --------------------------\n",
    "# Winsorization + LogTransform robusto (come train)\n",
    "# --------------------------\n",
    "for col in X_test.columns:\n",
    "    lower = X_test[col].quantile(0.01)\n",
    "    upper = X_test[col].quantile(0.99)\n",
    "    X_test[col] = np.clip(X_test[col], lower, upper)\n",
    "    X_test[col] = np.log1p(X_test[col].clip(lower=0))\n",
    "\n",
    "# Riempimento NaN con 0\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# --------------------------\n",
    "# Generazione embeddings latenti\n",
    "# --------------------------\n",
    "X_test_latent = encoder.predict(X_test, verbose=1)\n",
    "latent_cols = [f'latent_{i}' for i in range(X_test_latent.shape[1])]\n",
    "X_test_latent = pd.DataFrame(X_test_latent, columns=latent_cols)\n",
    "\n",
    "# --------------------------\n",
    "# Applicazione scaler del train set\n",
    "# --------------------------\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler_latent.transform(X_test_latent),\n",
    "    columns=latent_cols\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Salvataggio embeddings e label\n",
    "# --------------------------\n",
    "X_test_scaled.to_csv(os.path.join(output_dir, \"X_test_embeddings.csv\"), index=False)\n",
    "y_test.to_csv(os.path.join(output_dir, \"y_test.csv\"), index=False)\n",
    "\n",
    "print(f\"\\n💾 Test set embeddings scalati salvati in '{output_dir}/X_test_embeddings.csv'\")\n",
    "print(f\"💾 Etichette test salvate in '{output_dir}/y_test.csv'\")\n",
    "print(f\"✅ Tutto pronto per valutazione sul modello multiclasse!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd4046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeek-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
