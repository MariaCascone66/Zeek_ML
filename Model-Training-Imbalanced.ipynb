{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6d1de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Caricamento dataset e class weights per training (dataset sbilanciato)...\n",
      "‚úÖ Dati caricati correttamente:\n",
      " - X_train: (248027, 16) | X_test: (62007, 16)\n",
      " - Distribuzione y_train: {'Resource Development': 209927, 'Discovery': 12816, 'Other': 2355, 'Reconnaissance': 22929}\n",
      " - Distribuzione y_test : {'Resource Development': 52482, 'Discovery': 3204, 'Other': 589, 'Reconnaissance': 5732}\n",
      "\n",
      "‚úÖ BLOCCO 1 COMPLETATO: Dataset pronto per il training.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 1Ô∏è‚É£ ‚Äî Caricamento Dataset e Class Weights (Imbalanced)\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "print(\"üìÇ Caricamento dataset e class weights per training (dataset sbilanciato)...\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Percorsi file salvati\n",
    "# ----------------------------------------------------------\n",
    "base_path = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\processed_zeekdata22\"\n",
    "\n",
    "train_test_path = fr\"{base_path}\\train_test_unbal.npz\"\n",
    "weights_path = fr\"{base_path}\\class_weights_unbal.npy\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Caricamento dati\n",
    "# ----------------------------------------------------------\n",
    "data_npz = np.load(train_test_path, allow_pickle=True)\n",
    "class_weights = np.load(weights_path, allow_pickle=True).item()\n",
    "\n",
    "X_train = data_npz[\"X_train\"]\n",
    "X_test = data_npz[\"X_test\"]\n",
    "y_train = data_npz[\"y_train\"]\n",
    "y_test = data_npz[\"y_test\"]\n",
    "\n",
    "print(\"‚úÖ Dati caricati correttamente:\")\n",
    "print(\" - X_train:\", X_train.shape, \"| X_test:\", X_test.shape)\n",
    "print(\" - Distribuzione y_train:\", dict(collections.Counter(y_train)))\n",
    "print(\" - Distribuzione y_test :\", dict(collections.Counter(y_test)))\n",
    "\n",
    "print(\"\\n‚úÖ BLOCCO 1 COMPLETATO: Dataset pronto per il training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e298f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Addestramento Random Forest (dataset sbilanciato, class_weight dinamico, 3-fold)...\n",
      "\n",
      "üîç GridSearch manuale su 32 combinazioni (~96 fit fold per fold)...\n",
      "\n",
      "‚öôÔ∏è Combinazione 1/32 ‚Üí {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}\n",
      "   üìà Fold 1/3 ‚Üí F1 = 0.9991\n",
      "   üìà Fold 2/3 ‚Üí F1 = 0.9993\n",
      "   üìà Fold 3/3 ‚Üí F1 = 0.9995\n",
      "‚úÖ Combinazione 1 completata in 21.86s | F1 medio = 0.9993\n",
      "\n",
      "‚öôÔ∏è Combinazione 2/32 ‚Üí {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}\n",
      "   üìà Fold 1/3 ‚Üí F1 = 0.9988\n",
      "   üìà Fold 2/3 ‚Üí F1 = 0.9993\n",
      "   üìà Fold 3/3 ‚Üí F1 = 0.9996\n",
      "‚úÖ Combinazione 2 completata in 31.46s | F1 medio = 0.9992\n",
      "\n",
      "‚öôÔ∏è Combinazione 3/32 ‚Üí {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}\n",
      "   üìà Fold 1/3 ‚Üí F1 = 0.9991\n",
      "   üìà Fold 2/3 ‚Üí F1 = 0.9993\n",
      "   üìà Fold 3/3 ‚Üí F1 = 0.9995\n",
      "‚úÖ Combinazione 3 completata in 23.47s | F1 medio = 0.9993\n",
      "\n",
      "‚öôÔ∏è Combinazione 4/32 ‚Üí {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "   üìà Fold 1/3 ‚Üí F1 = 0.9988\n",
      "   üìà Fold 2/3 ‚Üí F1 = 0.9993\n",
      "   üìà Fold 3/3 ‚Üí F1 = 0.9996\n",
      "‚úÖ Combinazione 4 completata in 31.72s | F1 medio = 0.9992\n",
      "\n",
      "‚öôÔ∏è Combinazione 5/32 ‚Üí {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}\n",
      "   üìà Fold 1/3 ‚Üí F1 = 0.9986\n",
      "   üìà Fold 2/3 ‚Üí F1 = 0.9991\n",
      "   üìà Fold 3/3 ‚Üí F1 = 0.9995\n",
      "‚úÖ Combinazione 5 completata in 27.98s | F1 medio = 0.9991\n",
      "\n",
      "‚öôÔ∏è Combinazione 6/32 ‚Üí {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}\n",
      "   üìà Fold 1/3 ‚Üí F1 = 0.9989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     64\u001b[39m y_tr, y_val = y_train[train_idx], y_train[val_idx]\n\u001b[32m     66\u001b[39m model = RandomForestClassifier(\n\u001b[32m     67\u001b[39m     n_estimators=\u001b[32m100\u001b[39m,\n\u001b[32m     68\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m     **params\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m y_pred = model.predict(X_val)\n\u001b[32m     75\u001b[39m score = f1_score(y_val, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# BLOCCO 2Ô∏è‚É£ ‚úÖ Random Forest ‚Äî TRAINING SU DATASET SBILANCIATO (3-fold + parallel)\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "import collections\n",
    "\n",
    "print(\"üèóÔ∏è Addestramento Random Forest (dataset sbilanciato, class_weight dinamico, 3-fold)...\\n\")\n",
    "\n",
    "# ==========================================================\n",
    "# 1Ô∏è‚É£ Griglia iperparametri\n",
    "# ==========================================================\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10, 15],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "param_combinations = list(product(\n",
    "    param_grid['max_depth'],\n",
    "    param_grid['min_samples_split'],\n",
    "    param_grid['min_samples_leaf'],\n",
    "    param_grid['max_features'],\n",
    "    param_grid['bootstrap']\n",
    "))\n",
    "\n",
    "print(f\"üîç GridSearch manuale su {len(param_combinations)} combinazioni (~{len(param_combinations)*3} fit fold per fold)...\\n\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # ‚úÖ ridotto a 3 fold\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "# ==========================================================\n",
    "# 2Ô∏è‚É£ Ciclo combinazioni + validazione fold per fold\n",
    "# ==========================================================\n",
    "for i, (max_depth, min_split, min_leaf, max_feat, boot) in enumerate(param_combinations, 1):\n",
    "    params = {\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_split,\n",
    "        'min_samples_leaf': min_leaf,\n",
    "        'max_features': max_feat,\n",
    "        'bootstrap': boot\n",
    "    }\n",
    "    print(f\"‚öôÔ∏è Combinazione {i}/{len(param_combinations)} ‚Üí {params}\")\n",
    "    start = time.time()\n",
    "    \n",
    "    fold_scores = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            class_weight=class_weights,\n",
    "            n_jobs=-1,  # ‚úÖ usa tutti i core\n",
    "            **params\n",
    "        )\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        score = f1_score(y_val, y_pred, average='macro')\n",
    "        fold_scores.append(score)\n",
    "        print(f\"   üìà Fold {fold}/3 ‚Üí F1 = {score:.4f}\")\n",
    "\n",
    "    mean_score = np.mean(fold_scores)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚úÖ Combinazione {i} completata in {elapsed:.2f}s | F1 medio = {mean_score:.4f}\\n\")\n",
    "\n",
    "    results.append((params, mean_score))\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "\n",
    "print(f\"üèÅ GridSearch completata. Miglior F1 = {best_score:.4f}\")\n",
    "print(f\"üèÜ Migliori iperparametri trovati: {best_params}\\n\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3Ô∏è‚É£ Training finale con i migliori parametri\n",
    "# ==========================================================\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight=class_weights,\n",
    "    n_jobs=-1,  # ‚úÖ parallel\n",
    "    **best_params\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================================\n",
    "# 4Ô∏è‚É£ Metriche dettagliate\n",
    "# ==========================================================\n",
    "def print_metrics(y_true, y_pred, name, classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"\\nüìä Metriche sul {name} set:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f\"Matrice di Confusione ‚Äî {name}\")\n",
    "    plt.xlabel(\"Predetto\")\n",
    "    plt.ylabel(\"Reale\")\n",
    "    plt.show()\n",
    "    return f1\n",
    "\n",
    "y_train_pred = best_rf.predict(X_train)\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "\n",
    "classes_sorted = np.unique(np.concatenate([y_train, y_test]))\n",
    "train_f1 = print_metrics(y_train, y_train_pred, \"TRAIN\", classes_sorted)\n",
    "test_f1 = print_metrics(y_test, y_test_pred, \"TEST\", classes_sorted)\n",
    "\n",
    "# ==========================================================\n",
    "# 5Ô∏è‚É£ Analisi over/underfitting\n",
    "# ==========================================================\n",
    "gap_f1 = train_f1 - test_f1\n",
    "if gap_f1 > 0.05:\n",
    "    print(f\"\\n‚ö†Ô∏è Possibile OVERFITTING: gap F1 train-test = {gap_f1:.4f}\")\n",
    "elif test_f1 < 0.7:\n",
    "    print(f\"\\n‚ö†Ô∏è Possibile UNDERFITTING: F1 test = {test_f1:.4f}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Modello bilanciato, nessun evidente overfitting/underfitting\")\n",
    "\n",
    "print(\"\\n‚úÖ BLOCCO 2 COMPLETATO: Random Forest addestrato con class weights (dataset sbilanciato, 3-fold).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d005f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeek-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
