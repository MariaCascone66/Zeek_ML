{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c0c065",
   "metadata": {},
   "source": [
    "Modello 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5fc3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inizializzazione modelli in corso...\n",
      "[INFO] âœ… Modelli inizializzati correttamente:\n",
      " - Logistic Regression\n",
      " - KNN\n",
      " - Decision Tree\n",
      " - Random Forest\n",
      " - SVM\n",
      " - Naive Bayes\n",
      " - Hybrid Stacking (RF + DT â†’ LR)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# - BLOCCO 1 â€” Definizione dei modelli\n",
    "# ==============================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"[INFO] Inizializzazione modelli in corso...\")\n",
    "\n",
    "# ðŸ”¹ Modelli base\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, class_weight='balanced', random_state=42),\n",
    "    \"KNN\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5)),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    \"SVM\": make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=42)),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# ðŸ”¹ Modello ibrido (Stacking)\n",
    "# Combina Random Forest e Logistic Regression come meta-classifier\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "]\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(max_iter=300, class_weight='balanced', random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "models[\"Hybrid Stacking (RF + DT â†’ LR)\"] = stacking_model\n",
    "\n",
    "# ðŸ”¹ Stampa dei modelli inizializzati\n",
    "print(\"[INFO] âœ… Modelli inizializzati correttamente:\")\n",
    "for name in models.keys():\n",
    "    print(f\" - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927470cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inizio addestramento Naive Bayes con 5-Fold Cross-Validation...\n",
      "[INFO] Dataset caricati: X_train=(278716, 15), X_test=(69680, 15)\n",
      "[INFO] Fold 1 completato\n",
      "[INFO] Fold 2 completato\n",
      "[INFO] Fold 3 completato\n",
      "[INFO] Metriche CV salvate in: C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\\naive_bayes_cv_metrics.csv\n",
      "\n",
      "ðŸ”¢ Matrice di Confusione Media (CV):\n",
      "\n",
      "                      Credential Access  Defense Evasion  Discovery  \\\n",
      "Credential Access                     2                0          0   \n",
      "Defense Evasion                       0              771          0   \n",
      "Discovery                             0                0       4282   \n",
      "Exfiltration                          0                0          0   \n",
      "Initial Access                        0                0          1   \n",
      "Lateral Movement                      0                0          0   \n",
      "Persistence                           0                0          0   \n",
      "Privilege Escalation                  0                0          0   \n",
      "Reconnaissance                      294                0       2137   \n",
      "Resource Development                 14                0          0   \n",
      "\n",
      "                      Exfiltration  Initial Access  Lateral Movement  \\\n",
      "Credential Access                0               0                 2   \n",
      "Defense Evasion                  0               0                 1   \n",
      "Discovery                        0               0                95   \n",
      "Exfiltration                     2               0                 0   \n",
      "Initial Access                   0               2                 2   \n",
      "Lateral Movement                 0               1                 1   \n",
      "Persistence                      0               0                 0   \n",
      "Privilege Escalation             0               0                 0   \n",
      "Reconnaissance                   0               0              1303   \n",
      "Resource Development             0               0                23   \n",
      "\n",
      "                      Persistence  Privilege Escalation  Reconnaissance  \\\n",
      "Credential Access               0                     0               3   \n",
      "Defense Evasion                 0                     0               0   \n",
      "Discovery                       0                     0             451   \n",
      "Exfiltration                    0                     0               0   \n",
      "Initial Access                  0                     0               0   \n",
      "Lateral Movement                0                     0               1   \n",
      "Persistence                     1                     0               0   \n",
      "Privilege Escalation            0                     1               0   \n",
      "Reconnaissance                  0                  2749           10825   \n",
      "Resource Development            0                     0              41   \n",
      "\n",
      "                      Resource Development  \n",
      "Credential Access                        0  \n",
      "Defense Evasion                          0  \n",
      "Discovery                                0  \n",
      "Exfiltration                             0  \n",
      "Initial Access                           0  \n",
      "Lateral Movement                         0  \n",
      "Persistence                              0  \n",
      "Privilege Escalation                     0  \n",
      "Reconnaissance                           0  \n",
      "Resource Development                 69898  \n",
      "[INFO] Matrice di confusione media salvata in: C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\\naive_bayes_cv_confusion_matrix.csv\n",
      "\n",
      "[INFO] Addestramento modello finale su tutto il training set...\n",
      "[INFO] Metriche test salvate in: C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\\naive_bayes_test_metrics.csv\n",
      "\n",
      "âœ… [COMPLETATO] Tutte le metriche e confusion matrix salvate in:\n",
      "C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# - BLOCCO 10 â€” Naive Bayes Multiclasse (5-Fold CV + Test Finale)\n",
    "# ==============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "import pickle\n",
    "\n",
    "print(\"[INFO] Inizio addestramento Naive Bayes con 5-Fold Cross-Validation...\")\n",
    "\n",
    "# ðŸ”¹ Directory\n",
    "SAVE_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\TrainTestSplit\"\n",
    "RESULTS_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# ðŸ”¹ Caricamento dataset binned\n",
    "X_train_binned = np.load(os.path.join(SAVE_DIR, \"X_train_binned.npy\"))\n",
    "X_test_binned = np.load(os.path.join(SAVE_DIR, \"X_test_binned.npy\"))\n",
    "y_train = pd.read_csv(os.path.join(SAVE_DIR, \"y_train.csv\")).values.ravel()\n",
    "y_test = pd.read_csv(os.path.join(SAVE_DIR, \"y_test.csv\")).values.ravel()\n",
    "\n",
    "print(f\"[INFO] Dataset caricati: X_train={X_train_binned.shape}, X_test={X_test_binned.shape}\")\n",
    "\n",
    "# ðŸ”¹ Recupero mapping LabelEncoder per etichette leggibili\n",
    "with open(os.path.join(SAVE_DIR, \"label_encoder_tactic.pkl\"), \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "# ðŸ”¹ Preparazione cross-validation\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste per raccogliere metriche fold per fold\n",
    "accuracy_list, precision_list, recall_list, f1_list, specificity_list, cm_list = [], [], [], [], [], []\n",
    "\n",
    "# ===========================================================\n",
    "# 1ï¸âƒ£ Loop sui fold (Cross-Validation)\n",
    "# ===========================================================\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_binned, y_train), 1):\n",
    "    X_tr, X_val = X_train_binned[train_idx], X_train_binned[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_tr, y_tr)\n",
    "    y_pred = nb.predict(X_val)\n",
    "\n",
    "    # Metriche classiche\n",
    "    accuracy_list.append(accuracy_score(y_val, y_pred))\n",
    "    precision_list.append(precision_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    recall_list.append(recall_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    f1_list.append(f1_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "\n",
    "    # SpecificitÃ  per classe\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    cm_list.append(cm)\n",
    "    specificity_fold = []\n",
    "    for i in range(len(cm)):\n",
    "        tn = np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1))\n",
    "        fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "        specificity_fold.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "    specificity_list.append(np.mean(specificity_fold))\n",
    "\n",
    "    print(f\"[INFO] Fold {fold} completato\")\n",
    "\n",
    "# ===========================================================\n",
    "# 2ï¸âƒ£ Media e deviazione standard metriche (Cross-Validation)\n",
    "# ===========================================================\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": [np.mean(accuracy_list), np.std(accuracy_list)],\n",
    "    \"Precision_macro\": [np.mean(precision_list), np.std(precision_list)],\n",
    "    \"Recall_macro\": [np.mean(recall_list), np.std(recall_list)],\n",
    "    \"F1_macro\": [np.mean(f1_list), np.std(f1_list)],\n",
    "    \"Specificity_macro\": [np.mean(specificity_list), np.std(specificity_list)]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_summary, index=[\"mean\", \"std\"])\n",
    "metrics_df.to_csv(os.path.join(RESULTS_DIR, \"naive_bayes_cv_metrics.csv\"))\n",
    "print(f\"[INFO] Metriche CV salvate in: {os.path.join(RESULTS_DIR, 'naive_bayes_cv_metrics.csv')}\")\n",
    "\n",
    "# ===========================================================\n",
    "# 3ï¸âƒ£ Matrice di confusione media\n",
    "# ===========================================================\n",
    "avg_cm = np.mean(cm_list, axis=0).round().astype(int)\n",
    "labels_sorted = sorted(label_mapping.keys())\n",
    "cm_df = pd.DataFrame(avg_cm,\n",
    "                     index=[label_mapping.get(i, \"unknown\") for i in labels_sorted],\n",
    "                     columns=[label_mapping.get(i, \"unknown\") for i in labels_sorted])\n",
    "print(\"\\nðŸ”¢ Matrice di Confusione Media (CV):\\n\")\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(cm_df)\n",
    "\n",
    "cm_df.to_csv(os.path.join(RESULTS_DIR, \"naive_bayes_cv_confusion_matrix.csv\"))\n",
    "print(f\"[INFO] Matrice di confusione media salvata in: {os.path.join(RESULTS_DIR, 'naive_bayes_cv_confusion_matrix.csv')}\")\n",
    "\n",
    "# ===========================================================\n",
    "# 4ï¸âƒ£ Addestramento finale su tutto il training set\n",
    "# ===========================================================\n",
    "print(\"\\n[INFO] Addestramento modello finale su tutto il training set...\")\n",
    "final_nb = GaussianNB()\n",
    "final_nb.fit(X_train_binned, y_train)\n",
    "\n",
    "# ===========================================================\n",
    "# 5ï¸âƒ£ Valutazione sul test set (risultati â€œdefinitiviâ€)\n",
    "# ===========================================================\n",
    "y_pred_test = final_nb.predict(X_test_binned)\n",
    "\n",
    "# Metriche complessive\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "prec = precision_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "# SpecificitÃ \n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "specificity = []\n",
    "for i in range(len(cm_test)):\n",
    "    tn = np.sum(np.delete(np.delete(cm_test, i, axis=0), i, axis=1))\n",
    "    fp = np.sum(cm_test[:, i]) - cm_test[i, i]\n",
    "    specificity.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "specificity_mean = np.mean(specificity)\n",
    "\n",
    "# Salvataggio metriche test\n",
    "test_metrics = pd.DataFrame({\n",
    "    \"Accuracy\": [acc],\n",
    "    \"Precision_macro\": [prec],\n",
    "    \"Recall_macro\": [rec],\n",
    "    \"F1_macro\": [f1],\n",
    "    \"Specificity_macro\": [specificity_mean]\n",
    "})\n",
    "test_metrics.to_csv(os.path.join(RESULTS_DIR, \"naive_bayes_test_metrics.csv\"), index=False)\n",
    "print(f\"[INFO] Metriche test salvate in: {os.path.join(RESULTS_DIR, 'naive_bayes_test_metrics.csv')}\")\n",
    "\n",
    "# ===========================================================\n",
    "# 6ï¸âƒ£ Matrice di confusione e classification report (Test)\n",
    "# ===========================================================\n",
    "cm_test_df = pd.DataFrame(cm_test,\n",
    "                          index=[label_mapping.get(i, \"unknown\") for i in labels_sorted],\n",
    "                          columns=[label_mapping.get(i, \"unknown\") for i in labels_sorted])\n",
    "cm_test_df.to_csv(os.path.join(RESULTS_DIR, \"naive_bayes_test_confusion_matrix.csv\"))\n",
    "\n",
    "report = classification_report(y_test, y_pred_test, target_names=[label_mapping[i] for i in labels_sorted], output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(os.path.join(RESULTS_DIR, \"naive_bayes_test_classification_report.csv\"))\n",
    "\n",
    "print(\"\\nâœ… [COMPLETATO] Tutte le metriche e confusion matrix salvate in:\")\n",
    "print(RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446f9c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inizio addestramento Logistic Regression con 5-Fold Cross-Validation...\n",
      "[INFO] Dataset caricati: X_train=(278716, 15), X_test=(69680, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fold 1 completato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fold 2 completato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fold 3 completato\n",
      "[INFO] Metriche CV salvate in: C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\\logistic_regression_cv_metrics.csv\n",
      "[INFO] Addestramento modello finale su tutto il training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… [COMPLETATO] Logistic Regression addestrata e metriche salvate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# - BLOCCO 11 â€” Logistic Regression Multiclasse (5-Fold CV + Test Finale)\n",
    "# ==============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "import pickle\n",
    "\n",
    "print(\"[INFO] Inizio addestramento Logistic Regression con 5-Fold Cross-Validation...\")\n",
    "\n",
    "# ðŸ”¹ Directory\n",
    "SAVE_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\TrainTestSplit\"\n",
    "RESULTS_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# ðŸ”¹ Caricamento dataset scaled\n",
    "X_train_scaled = np.load(os.path.join(SAVE_DIR, \"X_train_scaled.npy\"))\n",
    "X_test_scaled  = np.load(os.path.join(SAVE_DIR, \"X_test_scaled.npy\"))\n",
    "y_train = pd.read_csv(os.path.join(SAVE_DIR, \"y_train.csv\")).values.ravel()\n",
    "y_test  = pd.read_csv(os.path.join(SAVE_DIR, \"y_test.csv\")).values.ravel()\n",
    "\n",
    "print(f\"[INFO] Dataset caricati: X_train={X_train_scaled.shape}, X_test={X_test_scaled.shape}\")\n",
    "\n",
    "# ðŸ”¹ Recupero mapping LabelEncoder\n",
    "with open(os.path.join(SAVE_DIR, \"label_encoder_tactic.pkl\"), \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "# ðŸ”¹ Cross-validation 3-fold\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste metriche\n",
    "accuracy_list, precision_list, recall_list, f1_list, specificity_list, cm_list = [], [], [], [], [], []\n",
    "\n",
    "# ===========================================================\n",
    "# 1ï¸âƒ£ Loop sui fold (Cross-Validation)\n",
    "# ===========================================================\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled, y_train), 1):\n",
    "    X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    lr.fit(X_tr, y_tr)\n",
    "    y_pred = lr.predict(X_val)\n",
    "\n",
    "    # Metriche classiche\n",
    "    accuracy_list.append(accuracy_score(y_val, y_pred))\n",
    "    precision_list.append(precision_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    recall_list.append(recall_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    f1_list.append(f1_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "\n",
    "    # SpecificitÃ  per classe\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    cm_list.append(cm)\n",
    "    specificity_fold = []\n",
    "    for i in range(len(cm)):\n",
    "        tn = np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1))\n",
    "        fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "        specificity_fold.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "    specificity_list.append(np.mean(specificity_fold))\n",
    "\n",
    "    print(f\"[INFO] Fold {fold} completato\")\n",
    "\n",
    "# ===========================================================\n",
    "# 2ï¸âƒ£ Media e deviazione standard metriche (Cross-Validation)\n",
    "# ===========================================================\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": [np.mean(accuracy_list), np.std(accuracy_list)],\n",
    "    \"Precision_macro\": [np.mean(precision_list), np.std(precision_list)],\n",
    "    \"Recall_macro\": [np.mean(recall_list), np.std(recall_list)],\n",
    "    \"F1_macro\": [np.mean(f1_list), np.std(f1_list)],\n",
    "    \"Specificity_macro\": [np.mean(specificity_list), np.std(specificity_list)]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_summary, index=[\"mean\", \"std\"])\n",
    "metrics_df.to_csv(os.path.join(RESULTS_DIR, \"logistic_regression_cv_metrics.csv\"))\n",
    "print(f\"[INFO] Metriche CV salvate in: {os.path.join(RESULTS_DIR, 'logistic_regression_cv_metrics.csv')}\")\n",
    "\n",
    "# ===========================================================\n",
    "# 3ï¸âƒ£ Matrice di confusione media\n",
    "# ===========================================================\n",
    "avg_cm = np.mean(cm_list, axis=0).round().astype(int)\n",
    "labels_sorted = sorted(label_mapping.keys())\n",
    "cm_df = pd.DataFrame(avg_cm,\n",
    "                     index=[label_mapping.get(i, \"unknown\") for i in labels_sorted],\n",
    "                     columns=[label_mapping.get(i, \"unknown\") for i in labels_sorted])\n",
    "cm_df.to_csv(os.path.join(RESULTS_DIR, \"logistic_regression_cv_confusion_matrix.csv\"))\n",
    "\n",
    "# ===========================================================\n",
    "# 4ï¸âƒ£ Addestramento finale su tutto il training set\n",
    "# ===========================================================\n",
    "print(\"[INFO] Addestramento modello finale su tutto il training set...\")\n",
    "final_lr = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "final_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ===========================================================\n",
    "# 5ï¸âƒ£ Valutazione sul test set\n",
    "# ===========================================================\n",
    "y_pred_test = final_lr.predict(X_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "prec = precision_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "# SpecificitÃ \n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "specificity = []\n",
    "for i in range(len(cm_test)):\n",
    "    tn = np.sum(np.delete(np.delete(cm_test, i, axis=0), i, axis=1))\n",
    "    fp = np.sum(cm_test[:, i]) - cm_test[i, i]\n",
    "    specificity.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "specificity_mean = np.mean(specificity)\n",
    "\n",
    "# Salvataggio metriche test\n",
    "test_metrics = pd.DataFrame({\n",
    "    \"Accuracy\": [acc],\n",
    "    \"Precision_macro\": [prec],\n",
    "    \"Recall_macro\": [rec],\n",
    "    \"F1_macro\": [f1],\n",
    "    \"Specificity_macro\": [specificity_mean]\n",
    "})\n",
    "test_metrics.to_csv(os.path.join(RESULTS_DIR, \"logistic_regression_test_metrics.csv\"), index=False)\n",
    "\n",
    "# Matrice di confusione e classification report\n",
    "cm_test_df = pd.DataFrame(cm_test,\n",
    "                          index=[label_mapping.get(i, \"unknown\") for i in labels_sorted],\n",
    "                          columns=[label_mapping.get(i, \"unknown\") for i in labels_sorted])\n",
    "cm_test_df.to_csv(os.path.join(RESULTS_DIR, \"logistic_regression_test_confusion_matrix.csv\"))\n",
    "\n",
    "report = classification_report(y_test, y_pred_test, target_names=[label_mapping[i] for i in labels_sorted], output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(os.path.join(RESULTS_DIR, \"logistic_regression_test_classification_report.csv\"))\n",
    "\n",
    "print(\"\\nâœ… [COMPLETATO] Logistic Regression addestrata e metriche salvate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b66ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inizio addestramento KNN con 3-Fold Cross-Validation...\n",
      "[INFO] Dataset caricati: X_train=(278716, 15), X_test=(69680, 15)\n",
      "[INFO] Fold 1 completato\n",
      "[INFO] Fold 2 completato\n",
      "[INFO] Fold 3 completato\n",
      "[INFO] Metriche CV salvate in: C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\\knn_cv_metrics.csv\n",
      "[INFO] Addestramento modello finale su tutto il training set...\n",
      "\n",
      "âœ… [COMPLETATO] KNN addestrato e metriche salvate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# - BLOCCO 12 â€” KNN Multiclasse (5-Fold CV + Test Finale)\n",
    "# ==============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "import pickle\n",
    "\n",
    "print(\"[INFO] Inizio addestramento KNN con 3-Fold Cross-Validation...\")\n",
    "\n",
    "# ðŸ”¹ Directory\n",
    "SAVE_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\TrainTestSplit\"\n",
    "RESULTS_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# ðŸ”¹ Caricamento dataset scaled\n",
    "X_train_scaled = np.load(os.path.join(SAVE_DIR, \"X_train_scaled.npy\"))\n",
    "X_test_scaled  = np.load(os.path.join(SAVE_DIR, \"X_test_scaled.npy\"))\n",
    "y_train = pd.read_csv(os.path.join(SAVE_DIR, \"y_train.csv\")).values.ravel()\n",
    "y_test  = pd.read_csv(os.path.join(SAVE_DIR, \"y_test.csv\")).values.ravel()\n",
    "\n",
    "print(f\"[INFO] Dataset caricati: X_train={X_train_scaled.shape}, X_test={X_test_scaled.shape}\")\n",
    "\n",
    "# ðŸ”¹ Recupero mapping LabelEncoder\n",
    "with open(os.path.join(SAVE_DIR, \"label_encoder_tactic.pkl\"), \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "# ðŸ”¹ Cross-validation 3-fold\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste metriche\n",
    "accuracy_list, precision_list, recall_list, f1_list, specificity_list, cm_list = [], [], [], [], [], []\n",
    "\n",
    "# ===========================================================\n",
    "# 1ï¸âƒ£ Loop sui fold (Cross-Validation)\n",
    "# ===========================================================\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled, y_train), 1):\n",
    "    X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "    knn.fit(X_tr, y_tr)\n",
    "    y_pred = knn.predict(X_val)\n",
    "\n",
    "    # Metriche classiche\n",
    "    accuracy_list.append(accuracy_score(y_val, y_pred))\n",
    "    precision_list.append(precision_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    recall_list.append(recall_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    f1_list.append(f1_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "\n",
    "    # SpecificitÃ  per classe\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    cm_list.append(cm)\n",
    "    specificity_fold = []\n",
    "    for i in range(len(cm)):\n",
    "        tn = np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1))\n",
    "        fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "        specificity_fold.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "    specificity_list.append(np.mean(specificity_fold))\n",
    "\n",
    "    print(f\"[INFO] Fold {fold} completato\")\n",
    "\n",
    "# ===========================================================\n",
    "# 2ï¸âƒ£ Media e deviazione standard metriche (Cross-Validation)\n",
    "# ===========================================================\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": [np.mean(accuracy_list), np.std(accuracy_list)],\n",
    "    \"Precision_macro\": [np.mean(precision_list), np.std(precision_list)],\n",
    "    \"Recall_macro\": [np.mean(recall_list), np.std(recall_list)],\n",
    "    \"F1_macro\": [np.mean(f1_list), np.std(f1_list)],\n",
    "    \"Specificity_macro\": [np.mean(specificity_list), np.std(specificity_list)]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_summary, index=[\"mean\", \"std\"])\n",
    "metrics_df.to_csv(os.path.join(RESULTS_DIR, \"knn_cv_metrics.csv\"))\n",
    "print(f\"[INFO] Metriche CV salvate in: {os.path.join(RESULTS_DIR, 'knn_cv_metrics.csv')}\")\n",
    "\n",
    "# ===========================================================\n",
    "# 3ï¸âƒ£ Matrice di confusione media\n",
    "# ===========================================================\n",
    "avg_cm = np.mean(cm_list, axis=0).round().astype(int)\n",
    "labels_sorted = sorted(label_mapping.keys())\n",
    "cm_df = pd.DataFrame(avg_cm,\n",
    "                     index=[label_mapping.get(i, \"unknown\") for i in labels_sorted],\n",
    "                     columns=[label_mapping.get(i, \"unknown\") for i in labels_sorted])\n",
    "cm_df.to_csv(os.path.join(RESULTS_DIR, \"knn_cv_confusion_matrix.csv\"))\n",
    "\n",
    "# ===========================================================\n",
    "# 4ï¸âƒ£ Addestramento finale su tutto il training set\n",
    "# ===========================================================\n",
    "print(\"[INFO] Addestramento modello finale su tutto il training set...\")\n",
    "final_knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "final_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ===========================================================\n",
    "# 5ï¸âƒ£ Valutazione sul test set\n",
    "# ===========================================================\n",
    "y_pred_test = final_knn.predict(X_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "prec = precision_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "# SpecificitÃ \n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "specificity = []\n",
    "for i in range(len(cm_test)):\n",
    "    tn = np.sum(np.delete(np.delete(cm_test, i, axis=0), i, axis=1))\n",
    "    fp = np.sum(cm_test[:, i]) - cm_test[i, i]\n",
    "    specificity.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "specificity_mean = np.mean(specificity)\n",
    "\n",
    "# Salvataggio metriche test\n",
    "test_metrics = pd.DataFrame({\n",
    "    \"Accuracy\": [acc],\n",
    "    \"Precision_macro\": [prec],\n",
    "    \"Recall_macro\": [rec],\n",
    "    \"F1_macro\": [f1],\n",
    "    \"Specificity_macro\": [specificity_mean]\n",
    "})\n",
    "test_metrics.to_csv(os.path.join(RESULTS_DIR, \"knn_test_metrics.csv\"), index=False)\n",
    "\n",
    "# Matrice di confusione e classification report\n",
    "cm_test_df = pd.DataFrame(cm_test,\n",
    "                          index=[label_mapping.get(i, \"unknown\") for i in labels_sorted],\n",
    "                          columns=[label_mapping.get(i, \"unknown\") for i in labels_sorted])\n",
    "cm_test_df.to_csv(os.path.join(RESULTS_DIR, \"knn_test_confusion_matrix.csv\"))\n",
    "\n",
    "report = classification_report(y_test, y_pred_test, target_names=[label_mapping[i] for i in labels_sorted], output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(os.path.join(RESULTS_DIR, \"knn_test_classification_report.csv\"))\n",
    "\n",
    "print(\"\\nâœ… [COMPLETATO] KNN addestrato e metriche salvate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f96b90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inizio addestramento Decision Tree con 3-Fold Cross-Validation...\n",
      "[INFO] Dataset caricati: X_train=(278716, 15), X_test=(69680, 15)\n",
      "[INFO] Fold 1 completato\n",
      "[INFO] Fold 2 completato\n",
      "[INFO] Fold 3 completato\n",
      "[INFO] Metriche CV salvate in: C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\\decision_tree_cv_metrics.csv\n",
      "[INFO] Addestramento modello finale su tutto il training set...\n",
      "\n",
      "âœ… [COMPLETATO] Decision Tree addestrato e metriche salvate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\maria\\anaconda3\\envs\\zeek-ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# - BLOCCO 12 â€” Decision Tree (3-Fold Cross-Validation + Test)\n",
    "# ==============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "import pickle\n",
    "\n",
    "print(\"[INFO] Inizio addestramento Decision Tree con 3-Fold Cross-Validation...\")\n",
    "\n",
    "# ðŸ”¹ Directory\n",
    "SAVE_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\TrainTestSplit\"\n",
    "RESULTS_DIR = r\"C:\\Users\\maria\\Desktop\\Zeek_ML\\ModelResults\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# ðŸ”¹ Caricamento dataset binned\n",
    "X_train_binned = np.load(os.path.join(SAVE_DIR, \"X_train_binned.npy\"))\n",
    "X_test_binned = np.load(os.path.join(SAVE_DIR, \"X_test_binned.npy\"))\n",
    "y_train = pd.read_csv(os.path.join(SAVE_DIR, \"y_train.csv\")).values.ravel()\n",
    "y_test = pd.read_csv(os.path.join(SAVE_DIR, \"y_test.csv\")).values.ravel()\n",
    "\n",
    "print(f\"[INFO] Dataset caricati: X_train={X_train_binned.shape}, X_test={X_test_binned.shape}\")\n",
    "\n",
    "# ðŸ”¹ Recupero mapping LabelEncoder per etichette leggibili\n",
    "with open(os.path.join(SAVE_DIR, \"label_encoder_tactic.pkl\"), \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "# ===========================================================\n",
    "# 1ï¸âƒ£ Cross-Validation\n",
    "# ===========================================================\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list, specificity_list, cm_list = [], [], [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_binned, y_train), 1):\n",
    "    X_tr, X_val = X_train_binned[train_idx], X_train_binned[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    dt = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    dt.fit(X_tr, y_tr)\n",
    "    y_pred = dt.predict(X_val)\n",
    "\n",
    "    # Metriche classiche\n",
    "    accuracy_list.append(accuracy_score(y_val, y_pred))\n",
    "    precision_list.append(precision_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    recall_list.append(recall_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "    f1_list.append(f1_score(y_val, y_pred, average='macro', zero_division=0))\n",
    "\n",
    "    # SpecificitÃ  per classe\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    cm_list.append(cm)\n",
    "    specificity_fold = []\n",
    "    for i in range(len(cm)):\n",
    "        tn = np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1))\n",
    "        fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "        specificity_fold.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "    specificity_list.append(np.mean(specificity_fold))\n",
    "\n",
    "    print(f\"[INFO] Fold {fold} completato\")\n",
    "\n",
    "# ===========================================================\n",
    "# 2ï¸âƒ£ Media e deviazione standard metriche CV\n",
    "# ===========================================================\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": [np.mean(accuracy_list), np.std(accuracy_list)],\n",
    "    \"Precision_macro\": [np.mean(precision_list), np.std(precision_list)],\n",
    "    \"Recall_macro\": [np.mean(recall_list), np.std(recall_list)],\n",
    "    \"F1_macro\": [np.mean(f1_list), np.std(f1_list)],\n",
    "    \"Specificity_macro\": [np.mean(specificity_list), np.std(specificity_list)]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_summary, index=[\"mean\", \"std\"])\n",
    "metrics_df.to_csv(os.path.join(RESULTS_DIR, \"decision_tree_cv_metrics.csv\"))\n",
    "print(f\"[INFO] Metriche CV salvate in: {os.path.join(RESULTS_DIR, 'decision_tree_cv_metrics.csv')}\")\n",
    "\n",
    "# ===========================================================\n",
    "# 3ï¸âƒ£ Addestramento modello finale + Test Set\n",
    "# ===========================================================\n",
    "print(\"[INFO] Addestramento modello finale su tutto il training set...\")\n",
    "dt_final = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "dt_final.fit(X_train_binned, y_train)\n",
    "y_pred_test = dt_final.predict(X_test_binned)\n",
    "\n",
    "# Metriche test\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_precision = precision_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "test_recall = recall_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "# SpecificitÃ  test\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "specificity_test = []\n",
    "for i in range(len(cm_test)):\n",
    "    tn = np.sum(np.delete(np.delete(cm_test, i, axis=0), i, axis=1))\n",
    "    fp = np.sum(cm_test[:, i]) - cm_test[i, i]\n",
    "    specificity_test.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "specificity_test_mean = np.mean(specificity_test)\n",
    "\n",
    "# Salvataggio metriche test\n",
    "test_metrics = pd.DataFrame({\n",
    "    \"Accuracy\": [test_accuracy],\n",
    "    \"Precision_macro\": [test_precision],\n",
    "    \"Recall_macro\": [test_recall],\n",
    "    \"F1_macro\": [test_f1],\n",
    "    \"Specificity_macro\": [specificity_test_mean]\n",
    "})\n",
    "test_metrics.to_csv(os.path.join(RESULTS_DIR, \"decision_tree_test_metrics.csv\"), index=False)\n",
    "\n",
    "# Matrice di confusione (test)\n",
    "labels_sorted = sorted(label_mapping.keys())\n",
    "cm_df = pd.DataFrame(\n",
    "    cm_test,\n",
    "    index=[label_mapping[i] for i in labels_sorted],\n",
    "    columns=[label_mapping[i] for i in labels_sorted]\n",
    ")\n",
    "cm_df.to_csv(os.path.join(RESULTS_DIR, \"decision_tree_confusion_matrix.csv\"))\n",
    "\n",
    "# Classification report (test)\n",
    "report = classification_report(y_test, y_pred_test, target_names=[label_mapping[i] for i in labels_sorted], output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(os.path.join(RESULTS_DIR, \"decision_tree_classification_report.csv\"))\n",
    "\n",
    "print(\"\\nâœ… [COMPLETATO] Decision Tree addestrato e metriche salvate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3e4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeek-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
